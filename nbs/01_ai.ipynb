{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† AI-Powered Text Operations\n",
    "\n",
    "Multi-provider AI operations using the `litellm` library for flexible text editing and analysis.\n",
    "\n",
    "**Features:**\n",
    "- Multi-model support (Gemini, Claude, OpenAI, etc.)\n",
    "- Natural language instructions for text editing\n",
    "- Web search capabilities for real-time information\n",
    "- Transcript summarization and improvement\n",
    "- Change explanation and analysis\n",
    "- Efficient conversation management (single assistant message + cumulative user instructions)\n",
    "- Natural language support for commands like \"change it back\" or \"undo that\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "from typing import List, Dict, Literal, Union\n",
    "from pydantic import BaseModel, ConfigDict, Field, model_validator\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import json\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Core AI Functions\n",
    "\n",
    "AI-powered operations using litellm's flexible multi-provider interface.\n",
    "\n",
    "**Main Functions:**\n",
    "- `JSONChat()` ‚Äî General-purpose AI chat with multi-model support\n",
    "- `summarize_transcript()` ‚Äî Generate concise summaries\n",
    "- `explain_edits()` ‚Äî Natural language explanation of changes\n",
    "- `improve_transcript()` ‚Äî Flexible text improvement with custom instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# --- Replace all ------------------------------------------------------------\n",
    "\n",
    "class ReplaceAllOp(BaseModel):\n",
    "    \"\"\"Represents a 'replace all' text operation.\"\"\"\n",
    "    op: Literal[\"replace_all\"]\n",
    "    find: str = Field(..., min_length=1)\n",
    "    replace: str = Field(..., min_length=0)\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "\n",
    "# --- Regex replace ------------------------------------------------------------\n",
    "\n",
    "class RegexReplaceOp(BaseModel):\n",
    "    \"\"\"Represents a regex-based find/replace operation.\"\"\"\n",
    "    op: Literal[\"regex_replace\"]\n",
    "    pattern: str = Field(..., min_length=1)\n",
    "    replacement: str = Field(..., min_length=0)\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def _validate_regex(cls, v: \"RegexReplaceOp\"):\n",
    "        # Precompile regex to ensure it's valid\n",
    "        try:\n",
    "            re.compile(v.pattern)\n",
    "        except re.error as e:\n",
    "            raise ValueError(f\"Invalid regex pattern: {e}\") from e\n",
    "        return v\n",
    "\n",
    "# --- Insert at absolute position ---------------------------------------------\n",
    "\n",
    "class InsertAtOp(BaseModel):\n",
    "    \"\"\"Insert text at an absolute character position (0-indexed).\"\"\"\n",
    "    op: Literal[\"insert_at\"]\n",
    "    text: str = Field(..., min_length=1)\n",
    "    position: int = Field(..., ge=0)\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "# --- Insert after marker ------------------------------------------------------\n",
    "\n",
    "class InsertAfterOp(BaseModel):\n",
    "    \"\"\"Insert text after the first occurrence of a marker string.\"\"\"\n",
    "    op: Literal[\"insert_after\"]\n",
    "    text: str = Field(..., min_length=1)\n",
    "    after: str = Field(..., min_length=1)\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "# --- Delete -------------------------------------------------------------------\n",
    "\n",
    "class DeleteOp(BaseModel):\n",
    "    \"\"\"Delete exact text (first or all occurrences).\"\"\"\n",
    "    op: Literal[\"delete\"]\n",
    "    text: str = Field(..., min_length=1)\n",
    "    all_occurrences: bool = False\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "\n",
    "# --- Edit plan container ------------------------------------------------------\n",
    "\n",
    "class EditPlan(BaseModel):\n",
    "    \"\"\"Represents a list of text operations to apply sequentially.\"\"\"\n",
    "    ops: List[\n",
    "        Union[\n",
    "            ReplaceAllOp,\n",
    "            RegexReplaceOp,\n",
    "            InsertAtOp,\n",
    "            InsertAfterOp,\n",
    "            DeleteOp,\n",
    "        ]\n",
    "    ]\n",
    "    model_config = ConfigDict(extra=\"forbid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß∞ Conversation Management\n",
    "\n",
    "The AI conversation uses a hybrid context pattern for efficiency.\n",
    "\n",
    "**Session State:**\n",
    "- `_messages` ‚Äî conversation history\n",
    "- `_current` ‚Äî current transcript after applied edits\n",
    "\n",
    "**Structure:**\n",
    "- **System message:** defines AI role and available operations\n",
    "- **Assistant message:** contains current transcript (updated after each edit)\n",
    "- **User messages:** cumulative instruction history\n",
    "\n",
    "**Example after 2 edits:**\n",
    "```json\n",
    "[\n",
    "  {\"role\": \"system\", \"content\": \"You are a precise text editor...\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Here is the current transcript:\\nI met oscar on Monday.\"},\n",
    "  {\"role\": \"user\", \"content\": \"Instruction: Change him to oscar\"},\n",
    "  {\"role\": \"user\", \"content\": \"Instruction: Change yesterday to on Monday\"}\n",
    "]\n",
    "```\n",
    "\n",
    "**Functions:**\n",
    "- `_new_conversation(transcript)` ‚Äî initializes conversation with system and assistant messages\n",
    "- `_set_current_transcript(new_transcript)` ‚Äî updates assistant message with latest transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# --- session state (module-level) ---\n",
    "_messages: List[Dict[str, str]] | None = None\n",
    "_current: str | None = None\n",
    "\n",
    "def _new_conversation(transcript: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Create a new message list with system + assistant context.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a precise text editor that outputs ONLY valid JSON matching the EditPlan schema.\\n\\n\"\n",
    "                \"Available operations:\\n\"\n",
    "                \"1. replace_all ‚Äî exact literal text only (no regex)\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - find: the exact text to replace\\n\"\n",
    "                \"       - replace: replacement text for every occurrence\\n\\n\"\n",
    "                \"2. regex_replace - pattern-based replacements (e.g., dates)\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - pattern: regex pattern to match (e.g., (\\\\d{4})-(\\\\d{2})-(\\\\d{2}) for dates)\\n\"\n",
    "                \"       - replacement: replacement string using \\\\1, \\\\2 for capture groups\\n\\n\"\n",
    "                \"3. insert_at ‚Äî insert text at an absolute index (0 = start)\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - text: text to insert\\n\"\n",
    "                \"       - position: integer index to insert at\\n\\n\"\n",
    "                \"4. insert_after ‚Äî insert text after a marker\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - text: text to insert\\n\"\n",
    "                \"       - after: insert after the first occurrence of this string\\n\"\n",
    "                \"       (ALWAYS provide a space in the string if needed when doing insert)\\n\\n\"\n",
    "                \"5. delete ‚Äî remove exact text\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - text: the exact text to remove\\n\"\n",
    "                \"       - all_occurrences: true = remove all, false = only first (default false)\\n\\n\"\n",
    "                \"RULES:\\n\"\n",
    "                \"- If you see regex patterns or date formats, you MUST use regex_replace, NOT replace_all!\\n\"\n",
    "                \"- When interpreting natural or spoken language, infer the user's intent precisely and map it to the correct fields.\\n\"\n",
    "                \"- ALWAYS provide a space in text to insert if needed.\\n\"\n",
    "                \"- Respond ONLY with valid JSON following the EditPlan schema.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Current text to edit:\\n{transcript}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "def _set_current_transcript(new_transcript: str) -> None:\n",
    "    global _messages\n",
    "    # replace the single assistant transcript message\n",
    "    for m in _messages:\n",
    "        if m.get(\"role\") == \"assistant\":\n",
    "            m[\"content\"] = f\"Current text to edit:\\n{new_transcript}\"\n",
    "            return\n",
    "    # Fallback: insert one if missing\n",
    "    _messages.insert(1, {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"Current text to edit:\\n{new_transcript}\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Core Functions\n",
    "\n",
    "**`_plan_edits(instruction, model)`**\n",
    "- Appends user instruction to conversation\n",
    "- Calls LLM with `response_format=EditPlan` for structured output\n",
    "- Returns parsed `EditPlan` object\n",
    "\n",
    "**`_apply_plan(transcript, plan)`**\n",
    "- Applies all operations in `EditPlan` sequentially to the transcript\n",
    "- Supports: `replace_all`, `regex_replace`, `insert_at`, `insert_after`, `delete`\n",
    "- Returns updated transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from litellm import completion\n",
    "\n",
    "\n",
    "def _plan_edits(instruction: str, model: str = \"gemini/gemini-2.0-flash-exp\") -> EditPlan:\n",
    "    \"\"\"\n",
    "    Append a user instruction, call the model with structured output, and return the parsed plan.\n",
    "    \"\"\"\n",
    "    global _messages\n",
    "\n",
    "    # Add the new instruction to the conversation\n",
    "    _messages.append({\"role\": \"user\", \"content\": f\"Instruction: {instruction}\"})\n",
    "\n",
    "    # Use litellm.completion to get structured JSON response\n",
    "    response = completion(\n",
    "        model=model,\n",
    "        messages=_messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Extract the JSON content from response\n",
    "    content = response.choices[0].message.content\n",
    "    \n",
    "    # Parse JSON and validate with Pydantic\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        # Handle case where LLM returns array directly instead of {\"ops\": [...]}\n",
    "        if isinstance(data, list):\n",
    "            data = {\"ops\": data}\n",
    "        plan = EditPlan.model_validate(data)\n",
    "        return plan\n",
    "    except (json.JSONDecodeError, Exception) as e:\n",
    "        raise RuntimeError(f\"Failed to parse model response as EditPlan: {e}\\nResponse: {content}\")\n",
    "\n",
    "\n",
    "def _apply_plan(transcript: str, plan: EditPlan) -> str:\n",
    "    \"\"\"\n",
    "    Apply all operations from the EditPlan to the given transcript.\n",
    "    \"\"\"\n",
    "    updated = transcript\n",
    "    for op in plan.ops:\n",
    "        if op.op == \"replace_all\":\n",
    "            updated = updated.replace(op.find, op.replace)\n",
    "        elif op.op == \"regex_replace\":\n",
    "            updated = re.sub(op.pattern, op.replacement, updated)\n",
    "        elif op.op == \"insert_at\":\n",
    "            pos = max(0, min(op.position, len(updated)))\n",
    "            updated = updated[:pos] + op.text + updated[pos:]\n",
    "        elif op.op == \"insert_after\":\n",
    "            idx = updated.find(op.after)\n",
    "            if idx != -1:\n",
    "                insert_pos = idx + len(op.after)\n",
    "                updated = updated[:insert_pos] + op.text + updated[insert_pos:]\n",
    "        elif op.op == \"delete\":\n",
    "            if op.all_occurrences:\n",
    "                updated = updated.replace(op.text, \"\")\n",
    "            else:\n",
    "                # Delete first occurrence only\n",
    "                idx = updated.find(op.text)\n",
    "                if idx != -1:\n",
    "                    updated = updated[:idx] + updated[idx + len(op.text):]\n",
    "    return updated\n",
    "\n",
    "class JSONChat:\n",
    "    def __init__(self, model=\"claude-sonnet-4-20250514\"):\n",
    "        self.model = model\n",
    "        self.history = []\n",
    "\n",
    "    def __call__(self, prompt: str):\n",
    "        self.history.append({\"role\": \"user\", \"content\": prompt})\n",
    "        resp = completion(\n",
    "            model=self.model,\n",
    "            messages=self.history,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        content = resp.choices[0].message[\"content\"]\n",
    "        self.history.append({\"role\": \"assistant\", \"content\": content})\n",
    "        # Try to parse JSON safely\n",
    "        try:\n",
    "            return json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"error\": \"Invalid JSON\", \"raw\": content}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Public API\n",
    "\n",
    "Functions for managing edit sessions and applying instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def has_session() -> bool:\n",
    "    \"\"\"Return True if an edit session is initialized.\"\"\"\n",
    "    return _messages is not None and _current is not None\n",
    "\n",
    "def start_session(initial_transcript: str) -> str:\n",
    "    \"\"\"Seed a new session with the initial transcript and return it.\"\"\"\n",
    "    global _messages, _current\n",
    "    _current = initial_transcript\n",
    "    _messages = _new_conversation(initial_transcript)\n",
    "    return _current\n",
    "\n",
    "def apply_instruction(instruction: str, model: str = \"gemini/gemini-2.5-flash\") -> str:\n",
    "    \"\"\"Apply an instruction to the current transcript and return the updated text.\"\"\"\n",
    "    global _current\n",
    "    if not has_session():\n",
    "        raise RuntimeError(\"No session. Call start_session() first.\")\n",
    "    plan = _plan_edits(instruction, model)\n",
    "    _current = _apply_plan(_current, plan)\n",
    "    _set_current_transcript(_current)\n",
    "    return _current\n",
    "\n",
    "def current_transcript() -> str:\n",
    "    \"\"\"Get the latest edited transcript (or '' if none).\"\"\"\n",
    "    return _current or \"\"\n",
    "\n",
    "def reset_session() -> None:\n",
    "    \"\"\"Clear session state.\"\"\"\n",
    "    global _messages, _current\n",
    "    _messages, _current = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Inspecting the Conversation\n",
    "\n",
    "Print the `_messages` list to see what the model sees on each call.\n",
    "\n",
    "**Key observations:**\n",
    "- One assistant message with the current transcript\n",
    "- Multiple user instructions recording session history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Message history:\n",
      "[{'content': 'You are a precise text editor that outputs ONLY valid JSON '\n",
      "             'matching the EditPlan schema.\\n'\n",
      "             '\\n'\n",
      "             'Available operations:\\n'\n",
      "             '1. replace_all ‚Äî exact literal text only (no regex)\\n'\n",
      "             '   fields:\\n'\n",
      "             '       - find: the exact text to replace\\n'\n",
      "             '       - replace: replacement text for every occurrence\\n'\n",
      "             '\\n'\n",
      "             '2. regex_replace - pattern-based replacements (e.g., dates)\\n'\n",
      "             '   fields:\\n'\n",
      "             '       - pattern: regex pattern to match (e.g., '\n",
      "             '(\\\\d{4})-(\\\\d{2})-(\\\\d{2}) for dates)\\n'\n",
      "             '       - replacement: replacement string using \\\\1, \\\\2 for '\n",
      "             'capture groups\\n'\n",
      "             '\\n'\n",
      "             '3. insert_at ‚Äî insert text at an absolute index (0 = start)\\n'\n",
      "             '   fields:\\n'\n",
      "             '       - text: text to insert\\n'\n",
      "             '       - position: integer index to insert at\\n'\n",
      "             '\\n'\n",
      "             '4. insert_after ‚Äî insert text after a marker\\n'\n",
      "             '   fields:\\n'\n",
      "             '       - text: text to insert\\n'\n",
      "             '       - after: insert after the first occurrence of this '\n",
      "             'string\\n'\n",
      "             '       (ALWAYS provide a space in the string if needed when '\n",
      "             'doing insert)\\n'\n",
      "             '\\n'\n",
      "             '5. delete ‚Äî remove exact text\\n'\n",
      "             '   fields:\\n'\n",
      "             '       - text: the exact text to remove\\n'\n",
      "             '       - all_occurrences: true = remove all, false = only first '\n",
      "             '(default false)\\n'\n",
      "             '\\n'\n",
      "             'RULES:\\n'\n",
      "             '- If you see regex patterns or date formats, you MUST use '\n",
      "             'regex_replace, NOT replace_all!\\n'\n",
      "             \"- When interpreting natural or spoken language, infer the user's \"\n",
      "             'intent precisely and map it to the correct fields.\\n'\n",
      "             '- ALWAYS provide a space in text to insert if needed.\\n'\n",
      "             '- Respond ONLY with valid JSON following the EditPlan schema.',\n",
      "  'role': 'system'},\n",
      " {'content': 'Current text to edit:\\nI like apples and apples are great!',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Instruction: Delete all occurrences of 'apples'\", 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"üß© Message history:\")\n",
    "pprint(_messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "**Architecture:**\n",
    "- Hybrid context: single assistant message (current state) + cumulative user instructions (history)\n",
    "- Efficient for long transcripts with complex edit sequences\n",
    "- Supports natural, conversational editing patterns\n",
    "\n",
    "**Supported Operations:**\n",
    "1. `replace_all` ‚Äî exact text replacement\n",
    "2. `regex_replace` ‚Äî pattern-based with capture groups (\\1, \\2, etc.)\n",
    "3. `insert_at` ‚Äî insert at character position (0-indexed)\n",
    "4. `insert_after` ‚Äî insert after marker string\n",
    "5. `delete` ‚Äî remove first or all occurrences\n",
    "\n",
    "**Future Enhancements:**\n",
    "- Token usage tracking\n",
    "- Operation history with undo/redo\n",
    "- UI integration (TUI/web)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Testing Different Edit Types with Litellm\n",
    "\n",
    "Let's test various text editing operations using litellm's natural language interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Meeting on 2025-10-07 and another on 2025-12-25.\n",
      "Result:   Meeting on 10/07/2025 and another on 12/25/2025.\n",
      "Plan: {\n",
      "  \"ops\": [\n",
      "    {\n",
      "      \"op\": \"regex_replace\",\n",
      "      \"pattern\": \"(\\\\d{4})-(\\\\d{2})-(\\\\d{2})\",\n",
      "      \"replacement\": \"\\\\2/\\\\3/\\\\1\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 1: Regex Replace - Format dates\n",
    "initial_transcript = \"Meeting on 2025-10-07 and another on 2025-12-25.\"\n",
    "_messages = _new_conversation(initial_transcript)\n",
    "_current = initial_transcript\n",
    "# Use regex to convert dates from YYYY-MM-DD to MM/DD/YYYY\n",
    "plan = _plan_edits(\"Convert all dates from YYYY-MM-DD format to MM/DD/YYYY format\")\n",
    "_current = _apply_plan(_current, plan)\n",
    "print(f\"Original: {initial_transcript}\")\n",
    "print(f\"Result:   {_current}\")\n",
    "print(f\"Plan: {plan.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: HelloWorld\n",
      "Result:   {'edited_text': 'Hello World'}\n",
      "Result:   {'edited_text': 'Hello World'}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 2: Insert Space\n",
    "\n",
    "test_text = \"HelloWorld\"\n",
    "print(f\"Original: {test_text}\")\n",
    "\n",
    "instruction = \"Add a space between Hello and World. Return only the edited text.\"\n",
    "chat = JSONChat()\n",
    "result = chat(instruction + f\"\\n\\nText: {test_text}\")\n",
    "print(f\"Result:   {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello, my name is John. I love coding.\n",
      "Result:   {'edited_text': 'Hello, my name is John Smith. I love coding.'}\n",
      "Result:   {'edited_text': 'Hello, my name is John Smith. I love coding.'}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 3: Insert After Marker\n",
    "\n",
    "test_text = \"Hello, my name is John. I love coding.\"\n",
    "print(f\"Original: {test_text}\")\n",
    "\n",
    "instruction = \"Add ' Smith' right after 'John'. Return only the edited text.\"\n",
    "chat = JSONChat()\n",
    "result = chat(instruction + f\"\\n\\nText: {test_text}\")\n",
    "print(f\"Result:   {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I like apples and apples are great!\n",
      "Result:   I like and are great!\n",
      "Plan: {\n",
      "  \"ops\": [\n",
      "    {\n",
      "      \"op\": \"delete\",\n",
      "      \"text\": \"apples\",\n",
      "      \"all_occurrences\": true\n",
      "    },\n",
      "    {\n",
      "      \"op\": \"replace_all\",\n",
      "      \"find\": \"I like  and  are great!\",\n",
      "      \"replace\": \"I like and are great!\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#| eval: false\n",
    "### Test 5: Delete - All occurrences\n",
    "\n",
    "test_text = \"I like apples and apples are great!\"\n",
    "_messages = _new_conversation(test_text)\n",
    "_current = test_text\n",
    "\n",
    "plan = _plan_edits(\"Delete all occurrences of 'apples' and make sure spacing is correct.\")\n",
    "_current = _apply_plan(_current, plan)\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"Result:   {_current}\")\n",
    "print(f\"Plan: {plan.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The meeting is on 2025-10-07 at the office. Please confirm.\n",
      "Plan JSON: {\n",
      "  \"ops\": [\n",
      "    {\n",
      "      \"op\": \"replace_all\",\n",
      "      \"find\": \"2025-10-07\",\n",
      "      \"replace\": \"10/07/2025\"\n",
      "    },\n",
      "    {\n",
      "      \"op\": \"replace_all\",\n",
      "      \"find\": \"office\",\n",
      "      \"replace\": \"conference room\"\n",
      "    },\n",
      "    {\n",
      "      \"op\": \"insert_after\",\n",
      "      \"text\": \" (urgent)\",\n",
      "      \"after\": \"confirm\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Result:   The meeting is on 10/07/2025 at the conference room. Please confirm (urgent).\n",
      "Plan JSON: {\n",
      "  \"ops\": [\n",
      "    {\n",
      "      \"op\": \"replace_all\",\n",
      "      \"find\": \"2025-10-07\",\n",
      "      \"replace\": \"10/07/2025\"\n",
      "    },\n",
      "    {\n",
      "      \"op\": \"replace_all\",\n",
      "      \"find\": \"office\",\n",
      "      \"replace\": \"conference room\"\n",
      "    },\n",
      "    {\n",
      "      \"op\": \"insert_after\",\n",
      "      \"text\": \" (urgent)\",\n",
      "      \"after\": \"confirm\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Result:   The meeting is on 10/07/2025 at the conference room. Please confirm (urgent).\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 6: Complex Multi-Operation Edit (using JSONChat with EditPlan)\n",
    "\n",
    "test_text = \"The meeting is on 2025-10-07 at the office. Please confirm.\"\n",
    "print(f\"Original: {test_text}\")\n",
    "\n",
    "# Get the schema as JSON for the prompt\n",
    "schema_json = EditPlan.model_json_schema()\n",
    "\n",
    "instruction = f\"\"\"Return ONLY valid JSON matching this exact schema:\n",
    "\n",
    "Create operations to edit this text: \"{test_text}\"\n",
    "\n",
    "Tasks:\n",
    "1. Change date from YYYY-MM-DD to MM/DD/YYYY format\n",
    "2. Change 'office' to 'conference room' (use \"op\": \"replace_all\", \"find\": \"office\", \"replace\": \"conference room\")\n",
    "3. Add ' (urgent)' right before the period at the end (use \"op\": \"insert_after\", \"text\": \" (urgent)\", \"after\": \"confirm\")\n",
    "\n",
    "Return ONLY the JSON object with an \"ops\" array containing these 3 operations.\"\"\"\n",
    "\n",
    "chat = JSONChat()\n",
    "plan_json = chat(instruction)\n",
    "print(f\"Plan JSON: {json.dumps(plan_json, indent=2)}\")\n",
    "\n",
    "# Parse and apply the plan using EditPlan\n",
    "plan = EditPlan.model_validate(plan_json)\n",
    "result = _apply_plan(test_text, plan)\n",
    "print(f\"Result:   {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Inspecting Full Response Structure\n",
    "\n",
    "Let's examine the complete response object returned by litellm's Chat API to understand all available fields and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üì¶ FULL RESPONSE OBJECT\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'litellm.types.utils.ModelResponse'>\n",
      "\n",
      "Response object: ModelResponse(id='Hlj3aNnODLHwnsEPr7DCsQY', created=1761040412, model='gemini-2.5-flash', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='2 + 2 = 4', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=29, prompt_tokens=9, total_tokens=38, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=22, rejected_prediction_tokens=None, text_tokens=7), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=9, image_tokens=None)), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])\n",
      "\n",
      "======================================================================\n",
      "üìã RESPONSE ATTRIBUTES\n",
      "======================================================================\n",
      "\n",
      "All attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_repr_markdown_', '_response_ms', '_setattr_handler', 'choices', 'construct', 'copy', 'created', 'dict', 'from_orm', 'get', 'id', 'json', 'model', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'object', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'system_fingerprint', 'to_dict', 'to_json', 'update_forward_refs', 'validate']\n",
      "\n",
      "======================================================================\n",
      "üéØ KEY FIELDS\n",
      "======================================================================\n",
      "\n",
      "response.choices: [Choices(finish_reason='stop', index=0, message=Message(content='2 + 2 = 4', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))]\n",
      "\n",
      "Type of choices: <class 'list'>\n",
      "\n",
      "First choice: Choices(finish_reason='stop', index=0, message=Message(content='2 + 2 = 4', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))\n",
      "\n",
      "======================================================================\n",
      "üí¨ MESSAGE CONTENT\n",
      "======================================================================\n",
      "\n",
      "Message object: Message(content='2 + 2 = 4', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None)\n",
      "\n",
      "Content: 2 + 2 = 4\n",
      "\n",
      "Role: assistant\n",
      "\n",
      "======================================================================\n",
      "üìä COMPLETE STRUCTURE (JSON formatted)\n",
      "======================================================================\n",
      "{\n",
      "  \"id\": \"Hlj3aNnODLHwnsEPr7DCsQY\",\n",
      "  \"created\": 1761040412,\n",
      "  \"model\": \"gemini-2.5-flash\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"2 + 2 = 4\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": null,\n",
      "        \"function_call\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 29,\n",
      "    \"prompt_tokens\": 9,\n",
      "    \"total_tokens\": 38,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": null,\n",
      "      \"audio_tokens\": null,\n",
      "      \"reasoning_tokens\": 22,\n",
      "      \"rejected_prediction_tokens\": null,\n",
      "      \"text_tokens\": 7\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": null,\n",
      "      \"cached_tokens\": null,\n",
      "      \"text_tokens\": 9,\n",
      "      \"image_tokens\": null\n",
      "    }\n",
      "  },\n",
      "  \"vertex_ai_grounding_metadata\": [],\n",
      "  \"vertex_ai_url_context_metadata\": [],\n",
      "  \"vertex_ai_safety_results\": [],\n",
      "  \"vertex_ai_citation_metadata\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Example: Complete Response Structure\n",
    "\n",
    "import json\n",
    "\n",
    "# Create a Chat instance\n",
    "chat = Chat(\"gemini/gemini-2.5-flash\")\n",
    "\n",
    "# Make a simple query\n",
    "response = chat(\"What is 2 + 2?\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üì¶ FULL RESPONSE OBJECT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nType: {type(response)}\")\n",
    "print(f\"\\nResponse object: {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã RESPONSE ATTRIBUTES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAll attributes: {dir(response)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ KEY FIELDS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nresponse.choices: {response.choices}\")\n",
    "print(f\"\\nType of choices: {type(response.choices)}\")\n",
    "print(f\"\\nFirst choice: {response.choices[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üí¨ MESSAGE CONTENT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nMessage object: {response.choices[0].message}\")\n",
    "print(f\"\\nContent: {response.choices[0].message.content}\")\n",
    "print(f\"\\nRole: {response.choices[0].message.role}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä COMPLETE STRUCTURE (JSON formatted)\")\n",
    "print(\"=\" * 70)\n",
    "# Convert to dict if possible for better inspection\n",
    "if hasattr(response, 'model_dump'):\n",
    "    print(json.dumps(response.model_dump(), indent=2))\n",
    "elif hasattr(response, '__dict__'):\n",
    "    print(json.dumps(response.__dict__, indent=2, default=str))\n",
    "else:\n",
    "    print(json.dumps(vars(response), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from smolagents import CodeAgent, InferenceClientModel, WebSearchTool\n",
    "#https://huggingface.co/docs/smolagents/index\n",
    "\n",
    "\n",
    "# Connect to running vLLM server using OpenAI-compatible API\n",
    "# model = OpenAIServerModel(\n",
    "#     model_id=\"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "#     api_base=\"http://localhost:8000/v1\",\n",
    "#     api_key=\"dummy\",  # vLLM doesn't require a real API key\n",
    "#     temperature=0.1,  # Lower temperature for more consistent output\n",
    "# )\n",
    "\n",
    "# model = InferenceClientModel()\n",
    "# agent = CodeAgent(\n",
    "#     tools=[WebSearchTool()],\n",
    "#     model = model \n",
    "# )\n",
    "\n",
    "# # Test with a simple question first\n",
    "# print(\"Testing simple question...\")\n",
    "# response = agent.run(\"What is the square root of 75?\")\n",
    "# print(f\"Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
