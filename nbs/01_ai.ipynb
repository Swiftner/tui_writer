{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ba62da",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: ai.html\n",
    "title: AI\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ba8ea",
   "metadata": {},
   "source": [
    "## AI Module\n",
    "This module implements the core AI-powered transcription editing system. It distinguishes between regular speech transcription and natural language edit commands, enabling a conversational editing workflow.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "The system uses a Chat-based LLM (via lisette) that: <br>\n",
    "- Maintains conversation history to understand context <br>\n",
    "- Distinguishes between new content and edit instructions <br>\n",
    "- Returns either \"APPEND\" for new text or the complete edited transcript <br>\n",
    "- Tracks token usage across the entire session <br>\n",
    "\n",
    "### Multi-Provider Support\n",
    "\n",
    "Works with multiple LLM providers through lisette: <br>\n",
    "- **OpenAI**: GPT-4o, GPT-4o-mini, GPT-3.5-turbo <br>\n",
    "- **Anthropic**: Claude 3.5 Sonnet, Claude 3 Opus/Sonnet/Haiku <br>\n",
    "- **Google**: Gemini 1.5 Pro/Flash <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc4e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc7103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "from lisette import *\n",
    "import asyncio\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d16540",
   "metadata": {},
   "source": [
    "## TranscriptEditor Class\n",
    "\n",
    "The `TranscriptEditor` class manages live transcription with AI-assisted editing capabilities. It uses keyword detection to trigger AI calls only when edit commands are detected, making it fast and cost-effective.\n",
    "\n",
    "### Initialization\n",
    "\n",
    "```python\n",
    "editor = TranscriptEditor(model=\"openai/gpt-4o-mini\", temperature=0.1)\n",
    "```\n",
    "\n",
    "**Parameters:** <br>\n",
    "- `model`: Full model identifier in format \"provider/model-name\" (e.g., \"openai/gpt-4o-mini\") <br>\n",
    "- `temperature`: LLM temperature for consistency (default: 0.1) <br>\n",
    "\n",
    "### Smart Triggering Strategy\n",
    "\n",
    "The editor uses keyword detection to determine when to call the AI: <br>\n",
    "1. **Fast path**: No trigger words → instant append (no AI call) <br>\n",
    "2. **AI path**: Trigger word detected → AI analyzes full transcript <br>\n",
    "3. **Stateless**: Each AI call receives complete transcript (no history dependency) <br>\n",
    "\n",
    "**Trigger words include**: change, replace, delete, remove, fix, correct, modify, edit, scratch, actually, wait, no, instead, undo\n",
    "\n",
    "### AI Decision Process\n",
    "\n",
    "When triggered, the AI receives the full transcript and determines: <br>\n",
    "- **Edit detected**: Returns complete corrected transcript <br>\n",
    "- **False alarm**: Returns \"APPEND\" (user wasn't actually editing) <br>\n",
    "\n",
    "This two-tier approach ensures 95% of speech appends instantly while still catching edit commands reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95492f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TranscriptEditor:\n",
    "    \"\"\"Manages live transcription with AI-assisted editing capabilities.\"\"\"\n",
    "    \n",
    "    # Keywords that suggest the user wants to edit\n",
    "    EDIT_KEYWORDS = {\n",
    "        'change', 'replace', 'delete', 'remove', 'fix', 'correct', \n",
    "        'modify', 'edit', 'scratch', 'actually', 'wait',\n",
    "        'no', 'instead', 'undo', 'oops', 'mistake', 'wrong'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, model: str, temperature: float = 0.1):\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.full_transcript = \"\"\n",
    "        self.total_tokens = 0\n",
    "    \n",
    "    def _contains_edit_keyword(self, text: str) -> bool:\n",
    "        \"\"\"Check if text contains any edit keywords.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        return any(keyword in text_lower for keyword in self.EDIT_KEYWORDS)\n",
    "    \n",
    "    async def process_chunk(self, chunk: str) -> dict:\n",
    "        \"\"\"Process a transcription chunk - only calls AI if edit keywords detected.\"\"\"\n",
    "        \n",
    "        # Check if this looks like an edit command\n",
    "        if self._contains_edit_keyword(chunk):\n",
    "            # Create a fresh Chat instance for this call (stateless)\n",
    "            chat = Chat(\n",
    "                self.model,\n",
    "                sp=\"\"\"You are helping with live transcription editing.\n",
    "\n",
    "You will receive:\n",
    "1. The current full transcript\n",
    "2. The latest chunk of text the user just said\n",
    "\n",
    "Determine if the user wants to edit the transcript:\n",
    "- If YES: Return ONLY the complete corrected transcript (preserve all newlines)\n",
    "- If NO (false alarm, they're just speaking normally): Return ONLY the word \"APPEND\"\n",
    "\n",
    "Be decisive and fast. Most of the time it's a real edit if you're being called.\"\"\",\n",
    "                temp=self.temperature\n",
    "            )\n",
    "            \n",
    "            # Provide full context to AI\n",
    "            prompt = f\"\"\"Current transcript:\n",
    "{self.full_transcript}\n",
    "\n",
    "Latest speech:\n",
    "{chunk}\"\"\"\n",
    "            \n",
    "            # Call AI in thread pool to avoid blocking\n",
    "            response = await asyncio.to_thread(chat, prompt)\n",
    "            \n",
    "            result = response.choices[0].message.content.strip()\n",
    "            tokens = response.usage.total_tokens if hasattr(response, \"usage\") else 0\n",
    "            self.total_tokens += tokens\n",
    "            \n",
    "            # Check if AI confirmed it's an edit\n",
    "            if result.startswith(\"APPEND\"):\n",
    "                # False alarm - just append with newline\n",
    "                self.full_transcript += chunk + \"\\n\"\n",
    "                action = \"append\"\n",
    "            else:\n",
    "                # Real edit - replace transcript\n",
    "                self.full_transcript = result\n",
    "                action = \"edit\"\n",
    "            \n",
    "            return {\n",
    "                \"transcript\": self.full_transcript,\n",
    "                \"action\": action,\n",
    "                \"tokens_used\": tokens,\n",
    "                \"total_tokens\": self.total_tokens,\n",
    "                \"ai_called\": True\n",
    "            }\n",
    "        else:\n",
    "            # No edit keywords - just append with newline\n",
    "            self.full_transcript += chunk + \"\\n\"\n",
    "            return {\n",
    "                \"transcript\": self.full_transcript,\n",
    "                \"action\": \"append\",\n",
    "                \"tokens_used\": 0,\n",
    "                \"total_tokens\": self.total_tokens,\n",
    "                \"ai_called\": False\n",
    "            }\n",
    "    \n",
    "    def get_transcript(self) -> str:\n",
    "        \"\"\"Get the current full transcript.\"\"\"\n",
    "        return self.full_transcript\n",
    "    \n",
    "    async def reset(self):\n",
    "        \"\"\"Reset the transcript and token counter.\"\"\"\n",
    "        self.full_transcript = \"\"\n",
    "        self.total_tokens = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe1eb4",
   "metadata": {},
   "source": [
    "## How It Works\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User speaks**: \"I love pizza\" <br>\n",
    "2. **Transcriber produces**: \"I love pizza.\" <br>\n",
    "3. **AI processes**: Detects new content → Returns \"APPEND\" <br>\n",
    "4. **Transcript updated**: Appends the new text <br>\n",
    "\n",
    "Then later: <br>\n",
    "\n",
    "1. **User speaks**: \"Actually, change pizza to hamburgers\" <br>\n",
    "2. **Transcriber produces**: \"Actually, change pizza to hamburgers.\" <br>\n",
    "3. **AI processes**: Detects edit command → Returns full edited transcript <br>\n",
    "4. **Transcript updated**: Replaces entire transcript with edited version <br>\n",
    "\n",
    "### Context Awareness\n",
    "\n",
    "The Chat instance maintains `hist` (history) of all previous interactions. This allows it to: <br>\n",
    "- Understand references to \"that\", \"it\", \"the last part\" <br>\n",
    "- Track what has been said throughout the session <br>\n",
    "- Make intelligent decisions about edit scope <br>\n",
    "\n",
    "### Token Management\n",
    "\n",
    "The editor tracks token usage across all API calls: <br>\n",
    "- `tokens_used`: Tokens consumed by the current chunk <br>\n",
    "- `total_tokens`: Cumulative tokens across the entire session <br>\n",
    "\n",
    "This helps users monitor API costs and understand the computational overhead of AI-assisted editing.\n",
    "\n",
    "### Error Handling\n",
    "\n",
    "If the AI processing fails, the system gracefully degrades to simple append mode, ensuring transcription continues even if the AI service is unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3825418a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk: My name is Batman.\n",
      "\n",
      "Action: append\n",
      "Current transcript:\n",
      "\n",
      "Tokens used: 155\n",
      "\n",
      "--- Chunk: I love pizza.\n",
      "\n",
      "Action: append\n",
      "Current transcript:\n",
      "\n",
      "Tokens used: 169\n",
      "\n",
      "--- Chunk: This transcriber is working quite well.\n",
      "Action: append\n",
      "Current transcript:\n",
      "\n",
      "Tokens used: 187\n",
      "\n",
      "--- Chunk: Actually, change pizza to hamburgers.\n",
      "Action: edit\n",
      "Current transcript:\n",
      "My name is Batman.  \n",
      "I love hamburgers.  \n",
      "This transcriber is working quite well.\n",
      "Tokens used: 223\n",
      "\n",
      "--- Chunk: Maybe even delete that first sentence about my name.\n",
      "Action: edit\n",
      "Current transcript:\n",
      "I love hamburgers.  \n",
      "This transcriber is working quite well.\n",
      "Tokens used: 255\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Test the TranscriptEditor\n",
    "import asyncio\n",
    "\n",
    "async def test_editor():\n",
    "    editor = TranscriptEditor(\"openai/gpt-4o-mini\")\n",
    "\n",
    "    # Simulate transcription chunks\n",
    "    chunks = [\n",
    "        \"My name is Batman.\\n\",\n",
    "        \"I love pizza.\\n\",\n",
    "        \"This transcriber is working quite well.\\n\",\n",
    "        \"Actually, change pizza to hamburgers.\\n\",\n",
    "        \"Maybe even delete that first sentence about my name.\\n\"\n",
    "    ]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        result = await editor.process_chunk(chunk)\n",
    "        print(f\"\\n--- Chunk: {chunk.strip()}\")\n",
    "        print(f\"AI Called: {result['ai_called']}\")\n",
    "        print(f\"Action: {result['action']}\")\n",
    "        print(f\"Tokens used: {result['tokens_used']}\")\n",
    "        print(f\"Current transcript:\\n{result['transcript']}\")\n",
    "\n",
    "# Run the test\n",
    "await test_editor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
