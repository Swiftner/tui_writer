{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† AI-Powered Text Operations\n",
    "\n",
    "Multi-provider AI operations using the `lisette` library for flexible text editing and analysis.\n",
    "\n",
    "**Features:**\n",
    "- Multi-model support (Gemini, Claude, OpenAI, etc.)\n",
    "- Natural language instructions for text editing\n",
    "- Web search capabilities for real-time information\n",
    "- Transcript summarization and improvement\n",
    "- Change explanation and analysis\n",
    "- Efficient conversation management (single assistant message + cumulative user instructions)\n",
    "- Natural language support for commands like \"change it back\" or \"undo that\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "from typing import List, Dict, Literal, Union\n",
    "from pydantic import BaseModel, ConfigDict, Field, model_validator\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import json\n",
    "from lisette import Chat\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Core AI Functions\n",
    "\n",
    "AI-powered operations using lisette's flexible multi-provider interface.\n",
    "\n",
    "**Main Functions:**\n",
    "- `ai_chat()` ‚Äî General-purpose AI chat with multi-model support\n",
    "- `summarize_transcript()` ‚Äî Generate concise summaries\n",
    "- `explain_edits()` ‚Äî Natural language explanation of changes\n",
    "- `improve_transcript()` ‚Äî Flexible text improvement with custom instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# --- Replace all ------------------------------------------------------------\n",
    "\n",
    "class ReplaceAllOp(BaseModel):\n",
    "    \"\"\"Represents a 'replace all' text operation.\"\"\"\n",
    "    op: Literal[\"replace_all\"]\n",
    "    find: str = Field(..., min_length=1)\n",
    "    replace: str = Field(..., min_length=0)\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "\n",
    "# --- Regex replace ------------------------------------------------------------\n",
    "\n",
    "class RegexReplaceOp(BaseModel):\n",
    "    \"\"\"Represents a regex-based find/replace operation.\"\"\"\n",
    "    op: Literal[\"regex_replace\"]\n",
    "    pattern: str = Field(..., min_length=1)\n",
    "    replacement: str = Field(..., min_length=0)\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def _validate_regex(cls, v: \"RegexReplaceOp\"):\n",
    "        # Precompile regex to ensure it's valid\n",
    "        try:\n",
    "            re.compile(v.pattern)\n",
    "        except re.error as e:\n",
    "            raise ValueError(f\"Invalid regex pattern: {e}\") from e\n",
    "        return v\n",
    "\n",
    "# --- Insert at absolute position ---------------------------------------------\n",
    "\n",
    "class InsertAtOp(BaseModel):\n",
    "    \"\"\"Insert text at an absolute character position (0-indexed).\"\"\"\n",
    "    op: Literal[\"insert_at\"]\n",
    "    text: str = Field(..., min_length=1)\n",
    "    position: int = Field(..., ge=0)\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "# --- Insert after marker ------------------------------------------------------\n",
    "\n",
    "class InsertAfterOp(BaseModel):\n",
    "    \"\"\"Insert text after the first occurrence of a marker string.\"\"\"\n",
    "    op: Literal[\"insert_after\"]\n",
    "    text: str = Field(..., min_length=1)\n",
    "    after: str = Field(..., min_length=1)\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "# --- Delete -------------------------------------------------------------------\n",
    "\n",
    "class DeleteOp(BaseModel):\n",
    "    \"\"\"Delete exact text (first or all occurrences).\"\"\"\n",
    "    op: Literal[\"delete\"]\n",
    "    text: str = Field(..., min_length=1)\n",
    "    all_occurrences: bool = False\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "\n",
    "# --- Edit plan container ------------------------------------------------------\n",
    "\n",
    "class EditPlan(BaseModel):\n",
    "    \"\"\"Represents a list of text operations to apply sequentially.\"\"\"\n",
    "    ops: List[\n",
    "        Union[\n",
    "            ReplaceAllOp,\n",
    "            RegexReplaceOp,\n",
    "            InsertAtOp,\n",
    "            InsertAfterOp,\n",
    "            DeleteOp,\n",
    "        ]\n",
    "    ]\n",
    "    model_config = ConfigDict(extra=\"forbid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß∞ Conversation Management\n",
    "\n",
    "The AI conversation uses a hybrid context pattern for efficiency.\n",
    "\n",
    "**Session State:**\n",
    "- `_messages` ‚Äî conversation history\n",
    "- `_current` ‚Äî current transcript after applied edits\n",
    "\n",
    "**Structure:**\n",
    "- **System message:** defines AI role and available operations\n",
    "- **Assistant message:** contains current transcript (updated after each edit)\n",
    "- **User messages:** cumulative instruction history\n",
    "\n",
    "**Example after 2 edits:**\n",
    "```json\n",
    "[\n",
    "  {\"role\": \"system\", \"content\": \"You are a precise text editor...\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Here is the current transcript:\\nI met oscar on Monday.\"},\n",
    "  {\"role\": \"user\", \"content\": \"Instruction: Change him to oscar\"},\n",
    "  {\"role\": \"user\", \"content\": \"Instruction: Change yesterday to on Monday\"}\n",
    "]\n",
    "```\n",
    "\n",
    "**Functions:**\n",
    "- `_new_conversation(transcript)` ‚Äî initializes conversation with system and assistant messages\n",
    "- `_set_current_transcript(new_transcript)` ‚Äî updates assistant message with latest transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# --- session state (module-level) ---\n",
    "_messages: List[Dict[str, str]] | None = None\n",
    "_current: str | None = None\n",
    "\n",
    "def _new_conversation(transcript: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Create a new message list with system + assistant context.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a precise text editor that outputs ONLY valid JSON matching the EditPlan schema.\\n\\n\"\n",
    "                \"Available operations:\\n\"\n",
    "                \"1. replace_all ‚Äî exact literal text only (no regex)\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - find: the exact text to replace\\n\"\n",
    "                \"       - replace: replacement text for every occurrence\\n\\n\"\n",
    "                \"2. regex_replace - pattern-based replacements (e.g., dates)\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - pattern: regex pattern to match (e.g., (\\\\d{4})-(\\\\d{2})-(\\\\d{2}) for dates)\\n\"\n",
    "                \"       - replacement: replacement string using \\\\1, \\\\2 for capture groups\\n\\n\"\n",
    "                \"3. insert_at ‚Äî insert text at an absolute index (0 = start)\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - text: text to insert\\n\"\n",
    "                \"       - position: integer index to insert at\\n\\n\"\n",
    "                \"4. insert_after ‚Äî insert text after a marker\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - text: text to insert\\n\"\n",
    "                \"       - after: insert after the first occurrence of this string\\n\"\n",
    "                \"       (ALWAYS provide a space in the string if needed when doing insert)\\n\\n\"\n",
    "                \"5. delete ‚Äî remove exact text\\n\"\n",
    "                \"   fields:\\n\"\n",
    "                \"       - text: the exact text to remove\\n\"\n",
    "                \"       - all_occurrences: true = remove all, false = only first (default false)\\n\\n\"\n",
    "                \"RULES:\\n\"\n",
    "                \"- If you see regex patterns or date formats, you MUST use regex_replace, NOT replace_all!\\n\"\n",
    "                \"- When interpreting natural or spoken language, infer the user's intent precisely and map it to the correct fields.\\n\"\n",
    "                \"- ALWAYS provide a space in text to insert if needed.\\n\"\n",
    "                \"- Respond ONLY with valid JSON following the EditPlan schema.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Current text to edit:\\n{transcript}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "def _set_current_transcript(new_transcript: str) -> None:\n",
    "    global _messages\n",
    "    # replace the single assistant transcript message\n",
    "    for m in _messages:\n",
    "        if m.get(\"role\") == \"assistant\":\n",
    "            m[\"content\"] = f\"Current text to edit:\\n{new_transcript}\"\n",
    "            return\n",
    "    # Fallback: insert one if missing\n",
    "    _messages.insert(1, {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"Current text to edit:\\n{new_transcript}\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Core Functions\n",
    "\n",
    "**`_plan_edits(instruction, model)`**\n",
    "- Appends user instruction to conversation\n",
    "- Calls LLM with `response_format=EditPlan` for structured output\n",
    "- Returns parsed `EditPlan` object\n",
    "\n",
    "**`_apply_plan(transcript, plan)`**\n",
    "- Applies all operations in `EditPlan` sequentially to the transcript\n",
    "- Supports: `replace_all`, `regex_replace`, `insert_at`, `insert_after`, `delete`\n",
    "- Returns updated transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def _plan_edits(instruction: str, model: str = \"gemini/gemini-2.5-flash\") -> EditPlan:\n",
    "    \"\"\"\n",
    "    Append a user instruction, call the model with structured output, and return the parsed plan.\n",
    "    \"\"\"\n",
    "    global _messages\n",
    "\n",
    "    # Add the new instruction to the conversation\n",
    "    _messages.append({\"role\": \"user\", \"content\": f\"Instruction: {instruction}\"})\n",
    "\n",
    "    # Use lisette to get structured JSON response\n",
    "    chat = Chat(model, response_format=\"json\")\n",
    "    \n",
    "    # Format messages for lisette (convert our format to lisette's expected format)\n",
    "    response = chat(messages=_messages, temperature=0)\n",
    "    \n",
    "    # Extract the JSON content from response\n",
    "    content = response.choices[0].message.content\n",
    "    \n",
    "    # Parse JSON and validate with Pydantic\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        plan = EditPlan.model_validate(data)\n",
    "        return plan\n",
    "    except (json.JSONDecodeError, Exception) as e:\n",
    "        raise RuntimeError(f\"Failed to parse model response as EditPlan: {e}\\nResponse: {content}\")\n",
    "\n",
    "\n",
    "def _apply_plan(transcript: str, plan: EditPlan) -> str:\n",
    "    \"\"\"\n",
    "    Apply all operations from the EditPlan to the given transcript.\n",
    "    \"\"\"\n",
    "    updated = transcript\n",
    "    for op in plan.ops:\n",
    "        if op.op == \"replace_all\":\n",
    "            updated = updated.replace(op.find, op.replace)\n",
    "        elif op.op == \"regex_replace\":\n",
    "            updated = re.sub(op.pattern, op.replacement, updated)\n",
    "        elif op.op == \"insert_at\":\n",
    "            pos = max(0, min(op.position, len(updated)))\n",
    "            updated = updated[:pos] + op.text + updated[pos:]\n",
    "        elif op.op == \"insert_after\":\n",
    "            idx = updated.find(op.after)\n",
    "            if idx != -1:\n",
    "                insert_pos = idx + len(op.after)\n",
    "                updated = updated[:insert_pos] + op.text + updated[insert_pos:]\n",
    "        elif op.op == \"delete\":\n",
    "            if op.all_occurrences:\n",
    "                updated = updated.replace(op.text, \"\")\n",
    "            else:\n",
    "                # Delete first occurrence only\n",
    "                idx = updated.find(op.text)\n",
    "                if idx != -1:\n",
    "                    updated = updated[:idx] + updated[idx + len(op.text):]\n",
    "    return updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Public API\n",
    "\n",
    "Functions for managing edit sessions and applying instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def has_session() -> bool:\n",
    "    \"\"\"Return True if an edit session is initialized.\"\"\"\n",
    "    return _messages is not None and _current is not None\n",
    "\n",
    "def start_session(initial_transcript: str) -> str:\n",
    "    \"\"\"Seed a new session with the initial transcript and return it.\"\"\"\n",
    "    global _messages, _current\n",
    "    _current = initial_transcript\n",
    "    _messages = _new_conversation(initial_transcript)\n",
    "    return _current\n",
    "\n",
    "def apply_instruction(instruction: str, model: str = \"gemini/gemini-2.5-flash\") -> str:\n",
    "    \"\"\"Apply an instruction to the current transcript and return the updated text.\"\"\"\n",
    "    global _current\n",
    "    if not has_session():\n",
    "        raise RuntimeError(\"No session. Call start_session() first.\")\n",
    "    plan = _plan_edits(instruction, model)\n",
    "    _current = _apply_plan(_current, plan)\n",
    "    _set_current_transcript(_current)\n",
    "    return _current\n",
    "\n",
    "def current_transcript() -> str:\n",
    "    \"\"\"Get the latest edited transcript (or '' if none).\"\"\"\n",
    "    return _current or \"\"\n",
    "\n",
    "def reset_session() -> None:\n",
    "    \"\"\"Clear session state.\"\"\"\n",
    "    global _messages, _current\n",
    "    _messages, _current = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåü Lisette Integration (Multi-Model AI)\n",
    "\n",
    "Additional AI capabilities using the `lisette` library for flexible, multi-provider AI operations.\n",
    "\n",
    "**Use Cases:**\n",
    "- General chat and Q&A with multiple AI providers (Gemini, Claude, OpenRouter models, etc.)\n",
    "- Web search-enabled queries\n",
    "- Transcript summarization and analysis\n",
    "- Explaining edits between versions\n",
    "\n",
    "**Note:** All AI operations in this module use lisette for consistent multi-provider support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def ai_chat(\n",
    "    prompt: str, \n",
    "    model: str = \"gemini/gemini-2.5-flash\", \n",
    "    enable_search: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    General-purpose AI chat using lisette for multi-provider support.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Question or instruction for the AI\n",
    "        model: Model identifier (e.g., \"gemini/gemini-2.5-flash\", \"claude-sonnet-4-20250514\", \"gpt-4o\")\n",
    "        enable_search: Whether to enable web search capabilities\n",
    "    \n",
    "    Returns:\n",
    "        AI response text\n",
    "        \n",
    "    Example:\n",
    "        >>> response = ai_chat(\"What is the capital of Norway?\", enable_search=True)\n",
    "        >>> print(response)\n",
    "    \"\"\"\n",
    "    search_level = \"l\" if enable_search else None\n",
    "    chat = Chat(model, search=search_level)\n",
    "    response = chat(prompt)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def summarize_transcript(\n",
    "    transcript: str, \n",
    "    model: str = \"gemini/gemini-2.5-flash\",\n",
    "    max_words: int = 100\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a concise summary of a transcript.\n",
    "    \n",
    "    Args:\n",
    "        transcript: The text to summarize\n",
    "        model: AI model to use\n",
    "        max_words: Maximum words for the summary\n",
    "        \n",
    "    Returns:\n",
    "        Summary text\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Summarize this transcript in {max_words} words or less:\n",
    "\n",
    "{transcript}\n",
    "\n",
    "Provide a clear, concise summary.\"\"\"\n",
    "    return ai_chat(prompt, model)\n",
    "\n",
    "\n",
    "def explain_edits(original: str, edited: str, model: str = \"gemini/gemini-2.5-flash\") -> str:\n",
    "    \"\"\"\n",
    "    Get an AI explanation of what changed between two text versions.\n",
    "    \n",
    "    Args:\n",
    "        original: Original text\n",
    "        edited: Edited/modified text\n",
    "        model: AI model to use\n",
    "        \n",
    "    Returns:\n",
    "        Natural language explanation of changes\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Compare these two versions and explain what changed:\n",
    "\n",
    "ORIGINAL:\n",
    "{original}\n",
    "\n",
    "EDITED:\n",
    "{edited}\n",
    "\n",
    "Provide a brief, clear explanation of the changes made.\"\"\"\n",
    "    return ai_chat(prompt, model)\n",
    "\n",
    "\n",
    "def improve_transcript(\n",
    "    transcript: str,\n",
    "    instructions: str = \"Fix grammar, punctuation, and clarity while preserving meaning\",\n",
    "    model: str = \"gemini/gemini-2.5-flash\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Use AI to improve transcript quality with flexible instructions.\n",
    "    \n",
    "    Args:\n",
    "        transcript: Text to improve\n",
    "        instructions: How to improve it (grammar, clarity, formality, etc.)\n",
    "        model: AI model to use\n",
    "        \n",
    "    Returns:\n",
    "        Improved transcript text\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"{instructions}\n",
    "\n",
    "TEXT:\n",
    "{transcript}\n",
    "\n",
    "Return ONLY the improved text, no explanations.\"\"\"\n",
    "    return ai_chat(prompt, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Lisette Examples\n",
    "\n",
    "Practical examples showing how to use the lisette-powered functions for various AI tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AI: Python is a highly versatile, general-purpose programming language, so it doesn't have *one single* primary use case in the way a specialized language might. However, if we were to identify its most prominent and impactful areas where it truly shines and dominates, they would be:\n",
      "\n",
      "1.  **Data Science, Machine Learning, and Artificial Intelligence (AI):** This is arguably Python's strongest and most defining primary use case today.\n",
      "    *   **Why:** Its rich ecosystem of powerful libraries like NumPy (numerical computing), Pandas (data manipulation and analysis), SciPy (scientific computing), Matplotlib/Seaborn (data visualization), Scikit-learn (machine learning), TensorFlow, and PyTorch (deep learning) makes it the go-to language for data scientists, analysts, and AI researchers.\n",
      "    *   **What it's used for:** Data cleaning, analysis, visualization, building predictive models, developing AI algorithms, natural language processing, computer vision, and more.\n",
      "\n",
      "2.  **Web Development (Backend):** Python is extremely popular for building the backend of web applications.\n",
      "    *   **Why:** Frameworks like Django (for large, complex, database-driven applications) and Flask (for smaller, more lightweight APIs and microservices) provide robust tools and structures.\n",
      "    *   **What it's used for:** Handling server-side logic, interacting with databases, managing user authentication, processing requests, and building APIs.\n",
      "\n",
      "3.  **Automation, Scripting, and DevOps:** Python's readability, extensive standard library, and cross-platform compatibility make it excellent for automating repetitive tasks.\n",
      "    *   **Why:** It can easily interact with operating systems, file systems, networks, and other applications.\n",
      "    *   **What it's used for:** System administration, network configuration, creating build/deployment scripts, data parsing, web scraping, and general task automation.\n",
      "\n",
      "**In summary, while Python can be used for almost anything, its primary impact and widespread adoption are most evident in:**\n",
      "\n",
      "*   **Data-driven fields (Data Science, ML, AI)**\n",
      "*   **Backend web development**\n",
      "*   **Automation and scripting**\n",
      "\n",
      "Its simplicity, readability, vast library ecosystem, and strong community support are key factors contributing to its dominance in these areas.\n",
      "üåê AI with search: In Oslo, Norway, the weather today, Friday, October 17, 2025, is partly cloudy with a temperature of 41¬∞F (5¬∞C), feeling like 41¬∞F (5¬∞C). There is a 15% chance of rain. The humidity is around 74%.\n",
      "\n",
      "The forecast for the rest of the day indicates sunny conditions during the day and clear with periodic clouds at night. There is a 35% chance of snow during the day. Temperatures are expected to range between 32¬∞F (0¬∞C) and 45¬∞F (7¬∞C), with humidity around 75%. Wind is from the NNW at 6 mph with gusts up to 21 mph.\n",
      "üåê AI with search: In Oslo, Norway, the weather today, Friday, October 17, 2025, is partly cloudy with a temperature of 41¬∞F (5¬∞C), feeling like 41¬∞F (5¬∞C). There is a 15% chance of rain. The humidity is around 74%.\n",
      "\n",
      "The forecast for the rest of the day indicates sunny conditions during the day and clear with periodic clouds at night. There is a 35% chance of snow during the day. Temperatures are expected to range between 32¬∞F (0¬∞C) and 45¬∞F (7¬∞C), with humidity around 75%. Wind is from the NNW at 6 mph with gusts up to 21 mph.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Example 1: Basic AI Chat\n",
    "\n",
    "# Simple question without web search\n",
    "response = ai_chat(\"What is Python's primary use case?\")\n",
    "print(\"ü§ñ AI:\", response)\n",
    "\n",
    "# Question with web search enabled\n",
    "response = ai_chat(\"What is the weather in Oslo today?\", enable_search=True)\n",
    "print(\"üåê AI with search:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Summary: The speaker had a productive day, buying groceries, hardware, and picking up a prescription. They also met a friend at a coffee shop to discuss her new job.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Example 2: Summarize a Transcript\n",
    "\n",
    "long_transcript = \"\"\"\n",
    "I went to the store yesterday and bought some groceries. I got milk, bread, eggs, and cheese.\n",
    "Then I went to the hardware store to pick up some nails and a hammer. After that, I stopped\n",
    "by the pharmacy to get my prescription. It was a pretty productive day overall. I also met\n",
    "my friend Sarah at the coffee shop and we talked for about an hour about her new job.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_transcript(long_transcript, max_words=30)\n",
    "print(\"üìù Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Changes: The edited version makes the sentence more specific by providing more detailed information:\n",
      "\n",
      "*   **Person:** \"him\" was changed to the specific name \"Oscar.\"\n",
      "*   **Time:** \"yesterday\" was changed to the specific day \"on Monday.\"\n",
      "*   **Place:** \"the store\" was changed to the more specific \"the grocery store.\"\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Example 3: Explain Changes Between Versions\n",
    "\n",
    "original = \"I met him yesterday at the store.\"\n",
    "edited = \"I met oscar on Monday at the grocery store.\"\n",
    "\n",
    "explanation = explain_edits(original, edited)\n",
    "print(\"üìä Changes:\", explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: um like i was saying uh the meeting was you know really good and stuff\n",
      "Improved: I was saying, the meeting was really good.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Example 4: Improve Transcript Quality\n",
    "\n",
    "messy_transcript = \"um like i was saying uh the meeting was you know really good and stuff\"\n",
    "\n",
    "improved = improve_transcript(\n",
    "    messy_transcript,\n",
    "    instructions=\"Remove filler words and improve clarity while keeping it casual\"\n",
    ")\n",
    "print(\"Original:\", messy_transcript)\n",
    "print(\"Improved:\", improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Complete Workflow: Lisette-Powered\n",
    "\n",
    "Demonstrating a complete workflow using **only lisette** for all AI operations - editing, explanation, summarization, and improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Original: I met him yesterday and he told me about the project deadline.\n",
      "‚úèÔ∏è  Edited: I met John last Tuesday and he told me about the project deadline.\n",
      "‚úèÔ∏è  Edited: I met John last Tuesday and he told me about the project deadline.\n",
      "üìä Changes: The changes made are:\n",
      "\n",
      "1.  **\"him\" was replaced with \"John\"**: This changes a pronoun to a specific proper noun, making the person's identity clear.\n",
      "2.  **\"yesterday\" was replaced with \"last Tuesday\"**: This changes a relative time reference to a specific day, making the timing of the meeting more precise.\n",
      "üìä Changes: The changes made are:\n",
      "\n",
      "1.  **\"him\" was replaced with \"John\"**: This changes a pronoun to a specific proper noun, making the person's identity clear.\n",
      "2.  **\"yesterday\" was replaced with \"last Tuesday\"**: This changes a relative time reference to a specific day, making the timing of the meeting more precise.\n",
      "üìÑ Summary: John informed me about the project deadline.\n",
      "üìÑ Summary: John informed me about the project deadline.\n",
      "‚ú® Improved: I met with John last Tuesday, and he informed me of the project deadline.\n",
      "‚ú® Improved: I met with John last Tuesday, and he informed me of the project deadline.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Complete Workflow: Using Lisette for Everything\n",
    "\n",
    "# 1Ô∏è‚É£ Start with a raw transcript\n",
    "raw_transcript = \"I met him yesterday and he told me about the project deadline.\"\n",
    "print(\"üìù Original:\", raw_transcript)\n",
    "\n",
    "# 2Ô∏è‚É£ Use lisette to make edits (flexible AI-based editing)\n",
    "edit_instruction = \"Change 'him' to 'John' and 'yesterday' to 'last Tuesday'. Return only the edited text.\"\n",
    "edited = ai_chat(edit_instruction + f\"\\n\\nText: {raw_transcript}\")\n",
    "print(\"‚úèÔ∏è  Edited:\", edited)\n",
    "\n",
    "# 3Ô∏è‚É£ Get AI explanation of changes (lisette)\n",
    "explanation = explain_edits(raw_transcript, edited)\n",
    "print(\"üìä Changes:\", explanation)\n",
    "\n",
    "# 4Ô∏è‚É£ Generate summary (lisette)\n",
    "summary = summarize_transcript(edited, max_words=15)\n",
    "print(\"üìÑ Summary:\", summary)\n",
    "\n",
    "# 5Ô∏è‚É£ Improve transcript quality (lisette)\n",
    "improved = improve_transcript(edited, instructions=\"Make it more formal and professional\")\n",
    "print(\"‚ú® Improved:\", improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Example: Sequential Editing with Lisette\n",
    "\n",
    "Demonstrates two editing steps using lisette:\n",
    "1. Replace all \"him\" with \"oscar\"\n",
    "2. Replace \"yesterday\" with \"on Monday\"\n",
    "\n",
    "Each step uses natural language instructions with lisette's flexible AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Original: I told him that I saw him yesterday. Then I asked him if he could help.\n",
      "‚úèÔ∏è  After edit 1: I told oscar that I saw oscar yesterday. Then I asked oscar if he could help.\n",
      "‚úèÔ∏è  After edit 1: I told oscar that I saw oscar yesterday. Then I asked oscar if he could help.\n",
      "‚úèÔ∏è  After edit 2: I told oscar that I saw oscar on Monday. Then I asked oscar if he could help.\n",
      "‚úÖ Final transcript: I told oscar that I saw oscar on Monday. Then I asked oscar if he could help.\n",
      "‚úèÔ∏è  After edit 2: I told oscar that I saw oscar on Monday. Then I asked oscar if he could help.\n",
      "‚úÖ Final transcript: I told oscar that I saw oscar on Monday. Then I asked oscar if he could help.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Example: Sequential Editing with Lisette\n",
    "\n",
    "# Initial transcript\n",
    "input_text = \"I told him that I saw him yesterday. Then I asked him if he could help.\"\n",
    "print(\"üìù Original:\", input_text)\n",
    "\n",
    "# 1Ô∏è‚É£ First edit\n",
    "instruction1 = \"Change all occurrences of 'him' to 'oscar'. Return only the edited text.\"\n",
    "input_text = ai_chat(instruction1 + f\"\\n\\nText: {input_text}\")\n",
    "print(\"‚úèÔ∏è  After edit 1:\", input_text)\n",
    "\n",
    "# 2Ô∏è‚É£ Second edit\n",
    "instruction2 = \"Now change 'yesterday' to 'on Monday'. Return only the edited text.\"\n",
    "input_text = ai_chat(instruction2 + f\"\\n\\nText: {input_text}\")\n",
    "print(\"‚úèÔ∏è  After edit 2:\", input_text)\n",
    "\n",
    "print(\"‚úÖ Final transcript:\", input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Inspecting the Conversation\n",
    "\n",
    "Print the `_messages` list to see what the model sees on each call.\n",
    "\n",
    "**Key observations:**\n",
    "- One assistant message with the current transcript\n",
    "- Multiple user instructions recording session history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Message history:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"üß© Message history:\")\n",
    "pprint(_messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "**Architecture:**\n",
    "- Hybrid context: single assistant message (current state) + cumulative user instructions (history)\n",
    "- Efficient for long transcripts with complex edit sequences\n",
    "- Supports natural, conversational editing patterns\n",
    "\n",
    "**Supported Operations:**\n",
    "1. `replace_all` ‚Äî exact text replacement\n",
    "2. `regex_replace` ‚Äî pattern-based with capture groups (\\1, \\2, etc.)\n",
    "3. `insert_at` ‚Äî insert at character position (0-indexed)\n",
    "4. `insert_after` ‚Äî insert after marker string\n",
    "5. `delete` ‚Äî remove first or all occurrences\n",
    "\n",
    "**Future Enhancements:**\n",
    "- Token usage tracking\n",
    "- Operation history with undo/redo\n",
    "- UI integration (TUI/web)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Testing Different Edit Types with Lisette\n",
    "\n",
    "Let's test various text editing operations using lisette's natural language interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Meeting on 2025-10-07 and another on 2025-12-25.\n",
      "Result:   Meeting on 10/07/2025 and another on 12/25/2025.\n",
      "Result:   Meeting on 10/07/2025 and another on 12/25/2025.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 1: Date Format Conversion\n",
    "\n",
    "test_text = \"Meeting on 2025-10-07 and another on 2025-12-25.\"\n",
    "print(f\"Original: {test_text}\")\n",
    "\n",
    "# Use lisette to convert dates\n",
    "instruction = \"Convert all dates from YYYY-MM-DD format to MM/DD/YYYY format. Return only the edited text.\"\n",
    "result = ai_chat(instruction + f\"\\n\\nText: {test_text}\")\n",
    "print(f\"Result:   {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: HelloWorld\n",
      "Result:   Hello World\n",
      "Result:   Hello World\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 2: Insert Space\n",
    "\n",
    "test_text = \"HelloWorld\"\n",
    "print(f\"Original: {test_text}\")\n",
    "\n",
    "instruction = \"Add a space between Hello and World. Return only the edited text.\"\n",
    "result = ai_chat(instruction + f\"\\n\\nText: {test_text}\")\n",
    "print(f\"Result:   {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello, my name is John. I love coding.\n",
      "Result:   Hello, my name is John Smith. I love coding.\n",
      "Result:   Hello, my name is John Smith. I love coding.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 3: Insert After Marker\n",
    "\n",
    "test_text = \"Hello, my name is John. I love coding.\"\n",
    "print(f\"Original: {test_text}\")\n",
    "\n",
    "instruction = \"Add ' Smith' right after 'John'. Return only the edited text.\"\n",
    "result = ai_chat(instruction + f\"\\n\\nText: {test_text}\")\n",
    "print(f\"Result:   {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I like apples and apples are great!\n",
      "Result:   I like and apples are great!\n",
      "Result:   I like and apples are great!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 4: Delete First Occurrence\n",
    "\n",
    "test_text = \"I like apples and apples are great!\"\n",
    "print(f\"Original: {test_text}\")\n",
    "\n",
    "instruction = \"Delete only the first occurrence of 'apples'. Return only the edited text.\"\n",
    "result = ai_chat(instruction + f\"\\n\\nText: {test_text}\")\n",
    "print(f\"Result:   {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I like apples and apples are great!\n",
      "Result:   I like and are great!\n",
      "Result:   I like and are great!\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 5: Delete All Occurrences\n",
    "\n",
    "test_text = \"I like apples and apples are great!\"\n",
    "print(f\"Original: {test_text}\")\n",
    "\n",
    "instruction = \"Delete all occurrences of 'apples'. Return only the edited text.\"\n",
    "result = ai_chat(instruction + f\"\\n\\nText: {test_text}\")\n",
    "print(f\"Result:   {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The meeting is on 2025-10-07 at the office. Please confirm.\n",
      "Result:   The meeting is on 10/07/2025 at the conference room. Please confirm. (urgent)\n",
      "Result:   The meeting is on 10/07/2025 at the conference room. Please confirm. (urgent)\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "### Test 6: Complex Multi-Operation Edit\n",
    "\n",
    "test_text = \"The meeting is on 2025-10-07 at the office. Please confirm.\"\n",
    "print(f\"Original: {test_text}\")\n",
    "\n",
    "instruction = \"\"\"Make these changes:\n",
    "1. Change the date format from YYYY-MM-DD to MM/DD/YYYY\n",
    "2. Change 'office' to 'conference room'\n",
    "3. Add ' (urgent)' at the end\n",
    "\n",
    "Return only the edited text.\"\"\"\n",
    "result = ai_chat(instruction + f\"\\n\\nText: {test_text}\")\n",
    "print(f\"Result:   {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from smolagents import CodeAgent, InferenceClientModel, WebSearchTool\n",
    "#https://huggingface.co/docs/smolagents/index\n",
    "\n",
    "\n",
    "# Connect to running vLLM server using OpenAI-compatible API\n",
    "# model = OpenAIServerModel(\n",
    "#     model_id=\"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "#     api_base=\"http://localhost:8000/v1\",\n",
    "#     api_key=\"dummy\",  # vLLM doesn't require a real API key\n",
    "#     temperature=0.1,  # Lower temperature for more consistent output\n",
    "# )\n",
    "\n",
    "# model = InferenceClientModel()\n",
    "# agent = CodeAgent(\n",
    "#     tools=[WebSearchTool()],\n",
    "#     model = model \n",
    "# )\n",
    "\n",
    "# # Test with a simple question first\n",
    "# print(\"Testing simple question...\")\n",
    "# response = agent.run(\"What is the square root of 75?\")\n",
    "# print(f\"Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tui-writer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
