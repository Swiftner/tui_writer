{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26ba8ea",
   "metadata": {},
   "source": [
    "# AI Module\n",
    "\n",
    "This notebook defines the AI-powered transcription editing system. It uses a Chat model to intelligently distinguish between new transcription content and edit commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc4e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc7103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "from lisette import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d16540",
   "metadata": {},
   "source": [
    "## TranscriptEditor Class\n",
    "\n",
    "The `TranscriptEditor` class manages live transcription with AI-assisted editing capabilities. It uses a Chat instance that maintains conversation history, allowing it to understand context across multiple chunks of transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95492f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TranscriptEditor:\n",
    "    \"\"\"Manages live transcription with AI-assisted editing capabilities.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str, temperature: float = 0.1):\n",
    "        self.chat = Chat(\n",
    "            model,\n",
    "            sp=\"\"\"You are helping with live transcription. As the user speaks, you'll receive each transcribed chunk (Each chunk being a line of text).\n",
    "Your job is to:\n",
    "1. Detect when the user wants to edit previous text (e.g., \"change that to...\", \"delete the last part\", \"replace hamburgers with pizza\")\n",
    "2. When an edit is requested, return ONLY the complete corrected/edited transcript\n",
    "3. When it's just new text, return ONLY the word \"APPEND\"\n",
    "4. Keep the conversation history to understand context\n",
    "\n",
    "Format your responses as:\n",
    "- For edits: Return the full corrected transcript, each sentence on its own line\n",
    "- For new text: APPEND\"\"\",\n",
    "            temp=temperature\n",
    "        )\n",
    "        self.full_transcript = \"\"\n",
    "        self.total_tokens = 0\n",
    "    \n",
    "    def process_chunk(self, chunk: str) -> dict:\n",
    "        \"\"\"Process a transcription chunk and determine if it's new text or an edit.\"\"\"\n",
    "        \n",
    "        # Send the chunk with context about current transcript\n",
    "        response = self.chat(chunk)\n",
    "        \n",
    "        result = response.choices[0].message.content.strip()\n",
    "        tokens = response.usage.total_tokens if hasattr(response, \"usage\") else 0\n",
    "        self.total_tokens += tokens\n",
    "        \n",
    "        # Determine if it's an append or edit\n",
    "        if result.startswith(\"APPEND\"):\n",
    "            self.full_transcript += result\n",
    "            action = \"append\"\n",
    "        else:\n",
    "            # It's an edit - replace full transcript\n",
    "            self.full_transcript = result\n",
    "            action = \"edit\"\n",
    "        \n",
    "        return {\n",
    "            \"transcript\": self.full_transcript,\n",
    "            \"action\": action,\n",
    "            \"tokens_used\": tokens,\n",
    "            \"total_tokens\": self.total_tokens\n",
    "        }\n",
    "    \n",
    "    def get_transcript(self) -> str:\n",
    "        \"\"\"Get the current full transcript.\"\"\"\n",
    "        return self.full_transcript\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the transcript and chat history.\"\"\"\n",
    "        self.full_transcript = \"\"\n",
    "        self.total_tokens = 0\n",
    "        self.chat = Chat(\n",
    "            self.chat.model,\n",
    "            sp=self.chat.sp,\n",
    "            temp=self.chat.temp\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe1eb4",
   "metadata": {},
   "source": [
    "### How it Works\n",
    "\n",
    "The class initializes with a `Chat` instance that has a system prompt instructing it to:\n",
    "1. **Detect edit commands** like \"change that to...\", \"delete the last part\", etc.\n",
    "2. **Return \"APPEND\"** when the user is just adding new text\n",
    "3. **Return the full corrected transcript** when an edit is requested\n",
    "\n",
    "**Key Feature**: The `Chat` instance maintains a `hist` (history) of all previous interactions. This allows it to \"remember\" the full context of the conversation within the same Chat instance, enabling it to understand references like \"that\", \"the last part\", or \"the first sentence\" when processing edit commands.\n",
    "\n",
    "The `process_chunk()` method:\n",
    "- Sends each new transcription chunk to the AI\n",
    "- Tracks token usage across all requests\n",
    "- Determines if the response is an append or edit action\n",
    "- Updates the full transcript accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3825418a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk: My name is Batman.\n",
      "\n",
      "Action: append\n",
      "Current transcript:\n",
      "\n",
      "Tokens used: 155\n",
      "\n",
      "--- Chunk: I love pizza.\n",
      "\n",
      "Action: append\n",
      "Current transcript:\n",
      "\n",
      "Tokens used: 169\n",
      "\n",
      "--- Chunk: This transcriber is working quite well.\n",
      "Action: append\n",
      "Current transcript:\n",
      "\n",
      "Tokens used: 187\n",
      "\n",
      "--- Chunk: Actually, change pizza to hamburgers.\n",
      "Action: edit\n",
      "Current transcript:\n",
      "My name is Batman.  \n",
      "I love hamburgers.  \n",
      "This transcriber is working quite well.\n",
      "Tokens used: 223\n",
      "\n",
      "--- Chunk: Maybe even delete that first sentence about my name.\n",
      "Action: edit\n",
      "Current transcript:\n",
      "I love hamburgers.  \n",
      "This transcriber is working quite well.\n",
      "Tokens used: 255\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Test the TranscriptEditor\n",
    "editor = TranscriptEditor(\"openai/gpt-4o-mini\")\n",
    "\n",
    "# Simulate transcription chunks\n",
    "chunks = [\n",
    "    \"My name is Batman.\\n\",\n",
    "    \"I love pizza.\\n\",\n",
    "    \"This transcriber is working quite well.\",\n",
    "    \"Actually, change pizza to hamburgers.\",\n",
    "    \"Maybe even delete that first sentence about my name.\"\n",
    "]\n",
    "\n",
    "for chunk in chunks:\n",
    "    result = editor.process_chunk(chunk)\n",
    "    print(f\"\\n--- Chunk: {chunk}\")\n",
    "    print(f\"Action: {result['action']}\")\n",
    "    print(f\"Current transcript:\\n{result['transcript']}\")\n",
    "    print(f\"Tokens used: {result['tokens_used']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666325ca",
   "metadata": {},
   "source": [
    "## Testing the TranscriptEditor\n",
    "\n",
    "This test demonstrates the editor's ability to:\n",
    "1. **Append new transcription** - \"My name is Batman\", \"I love pizza\", etc.\n",
    "2. **Handle edit commands** - \"change pizza to hamburgers\" modifies existing text\n",
    "3. **Process complex edits** - \"delete that first sentence\" removes content\n",
    "\n",
    "Notice how the AI understands contextual references because the Chat maintains conversation history (`hist`). When you say \"change pizza to hamburgers\", it knows what \"pizza\" refers to from earlier in the same Chat session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fcb80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
