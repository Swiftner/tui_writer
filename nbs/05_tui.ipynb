{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41ebf47",
   "metadata": {},
   "source": [
    "---\n",
    "title: TUI\n",
    "output-file: tui.html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee59f5",
   "metadata": {},
   "source": [
    "## TUI Module - Terminal User Interface\n",
    "\n",
    "This module implements the complete Textual-based terminal user interface for live audio transcription with AI-powered editing capabilities.\n",
    "\n",
    "### Overview\n",
    "\n",
    "The TUI provides a full-featured interactive interface that combines: <br>\n",
    "- Real-time speech transcription with Faster Whisper <br>\n",
    "- AI-powered edit detection and application <br>\n",
    "- Multi-provider AI support (OpenAI, Anthropic, Google) <br>\n",
    "- Keyboard-driven workflow with modal dialogs <br>\n",
    "- Visual feedback for recording state and AI operations <br>\n",
    "\n",
    "### Architecture\n",
    "\n",
    "The interface is built with Textual, a modern Python framework for building terminal UIs. The architecture consists of:\n",
    "\n",
    "1. **Main Application** (`TranscriptionTUI`): Coordinates all components and manages state <br>\n",
    "2. **Modal Screens**: Settings dialogs for audio and AI configuration <br>\n",
    "3. **Help System**: Comprehensive in-app documentation <br>\n",
    "4. **Event Handlers**: Keyboard shortcuts and user interactions <br>\n",
    "5. **Reactive UI**: Automatic updates based on state changes <br>\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Live Transcription Display**: Scrolling log that shows transcripts in real-time <br>\n",
    "- **Recording Indicator**: Header turns red during active recording <br>\n",
    "- **Status Notifications**: Toast-style messages for user feedback <br>\n",
    "- **Clipboard Integration**: One-key copy of entire transcript <br>\n",
    "- **Persistent Configuration**: Remembers settings and API keys between sessions <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37045a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from enum import Enum, auto\n",
    "import asyncio\n",
    "import pyperclip\n",
    "import os\n",
    "\n",
    "from textual import on\n",
    "from textual.app import App, ComposeResult\n",
    "from textual.reactive import reactive\n",
    "from textual.containers import Container, Grid, Center, HorizontalGroup\n",
    "from textual.screen import ModalScreen\n",
    "from textual.widgets import Header, Footer, Static, Button, Log, Select, Rule, MarkdownViewer, Input, Switch\n",
    "\n",
    "from tui_writer.live import LiveTranscriber\n",
    "from tui_writer.ai import TranscriptEditor\n",
    "from tui_writer.config import get_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611ced3",
   "metadata": {},
   "source": [
    "## Styling with Textual CSS\n",
    "\n",
    "The CSS defines the visual appearance of the TUI using Textual's CSS-like syntax. Key features: <br>\n",
    "- **Recording indicator**: Changes header background to red (`$error`) when recording <br>\n",
    "- **Transcript display**: Styled with hatching pattern and padding for readability <br>\n",
    "- **Modal layouts**: Centered dialogs for settings and help screens <br>\n",
    "- Uses Textual's built-in color variables like `$background`, `$surface`, `$boost`, etc. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9acef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "TEXTUAL_CSS = \"\"\"\n",
    "    Screen {\n",
    "        align: center top;\n",
    "    }\n",
    "    Header {\n",
    "        background: $background;\n",
    "    }\n",
    "    .recording {\n",
    "        background: $error;\n",
    "    }\n",
    "\n",
    "    #transcript-display {\n",
    "        hatch: horizontal $boost 80%;\n",
    "        background: $boost;\n",
    "        margin: 1 3;\n",
    "        padding: 2 3;\n",
    "    }\n",
    "    \n",
    "    HelpModal {\n",
    "        align: center middle;\n",
    "    }\n",
    "    #help {\n",
    "        border: thick $background 80%;\n",
    "        background: $surface;\n",
    "        width: 100;\n",
    "        padding: 0 2;\n",
    "        align: center top;\n",
    "        height: 90%;\n",
    "        max-height: 70;\n",
    "    }\n",
    "\n",
    "    \n",
    "    SettingsModal {\n",
    "        align: center middle;\n",
    "    }\n",
    "    #settings-modal {\n",
    "        border: thick $background 80%;\n",
    "        background: $surface;\n",
    "        width: 100;\n",
    "        padding: 0 2;\n",
    "        align: center top;\n",
    "        height: 25;\n",
    "    }\n",
    "    \n",
    "    AISettingsModal {\n",
    "        align: center middle;\n",
    "    }\n",
    "    #ai-settings-modal {\n",
    "        border: thick $background 80%;\n",
    "        background: $surface;\n",
    "        width: 120;\n",
    "        padding: 0 2;\n",
    "        align: center top;\n",
    "        height: 40;\n",
    "    }\n",
    "    \n",
    "    #modal-header {\n",
    "        content-align: center middle;\n",
    "        margin: 1 0;\n",
    "    }\n",
    "    Rule {\n",
    "        margin: 0;\n",
    "    }\n",
    "    #settings-grid {\n",
    "        layout: grid;\n",
    "        grid-size: 3 4;\n",
    "        grid-rows: 1fr;\n",
    "        grid-columns: 1fr;\n",
    "        grid-gutter: 1;\n",
    "    }\n",
    "    #ai-settings-grid {\n",
    "        layout: grid;\n",
    "        grid-size: 3;\n",
    "        grid-rows: 1fr;\n",
    "        grid-columns: 1fr;\n",
    "        grid-gutter: 1;\n",
    "    }\n",
    "\n",
    "    .select-text {\n",
    "        height: 100%;\n",
    "        content-align: center middle;\n",
    "    }\n",
    "    Select {\n",
    "        column-span: 2;\n",
    "        height: 100%;\n",
    "        align: center middle;\n",
    "    }\n",
    "    Switch {\n",
    "        column-span: 2;\n",
    "        align: center middle;\n",
    "    }\n",
    "    Input {\n",
    "        column-span: 2;\n",
    "        height: 100%;\n",
    "        align: center middle;\n",
    "    }\n",
    "    #settings-actions {\n",
    "        column-span: 3;\n",
    "    }\n",
    "    #ai-settings-actions {\n",
    "        width: auto;\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737763b8",
   "metadata": {},
   "source": [
    "## SettingsModal - Audio Configuration\n",
    "\n",
    "Modal dialog for configuring Whisper transcription settings. Accessed by pressing `s` in the main interface.\n",
    "\n",
    "### Available Models\n",
    "\n",
    "The modal offers 10 Whisper model options with trade-offs between speed and accuracy:\n",
    "\n",
    "**Standard Models** (multilingual): <br>\n",
    "- **Tiny**: Ultra fast, low accuracy - Good for testing or real-time needs <br>\n",
    "- **Base**: Fast, decent accuracy - Recommended starting point <br>\n",
    "- **Small**: Balanced speed and accuracy - Good general purpose choice <br>\n",
    "- **Medium**: Slow, high accuracy - For when quality matters <br>\n",
    "- **Large-v3**: Very slow, best accuracy - Maximum quality <br>\n",
    "\n",
    "**English-Only Models** (faster variants): <br>\n",
    "- **Tiny.en** through **Large.en**: Optimized for English, typically 2x faster than multilingual equivalents <br>\n",
    "\n",
    "### Language Support\n",
    "\n",
    "Supports 40+ languages including: <br>\n",
    "- European: English, German, French, Spanish, Italian, Portuguese, Dutch, Polish, Czech, Slovak, etc. <br>\n",
    "- Nordic: Norwegian, Swedish, Danish, Finnish <br>\n",
    "- Slavic: Russian, Ukrainian, Serbian, Croatian, Bulgarian, Slovenian <br>\n",
    "- Asian: Chinese (Mandarin/Cantonese), Japanese, Korean, Hindi, Bengali, Thai, Vietnamese, Indonesian <br>\n",
    "- Middle Eastern: Arabic, Hebrew, Persian, Turkish, Urdu <br>\n",
    "- African: Swahili, Afrikaans <br>\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Uses Textual's `Select` widgets for dropdown menus. Selected values are returned when the modal is dismissed and applied via the `apply_settings()` callback in the main app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80084963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| include: false\n",
    "\n",
    "class SettingsModal(ModalScreen):\n",
    "    # Available Whisper model options (label, value)\n",
    "    WHISPER_MODELS = [\n",
    "        (\"Tiny      âš¡  Ultra fast   - Low accuracy\", \"tiny\"),\n",
    "        (\"Base      âš¡  Fast         - Decent accuracy\", \"base\"),\n",
    "        (\"Small     âš–   Balanced    - Good accuracy\", \"small\"),\n",
    "        (\"Medium    ðŸ¢  Slow        - High accuracy\",  \"medium\"),\n",
    "        (\"Large     ðŸ¢  Very Slow   - Best accuracy\", \"large-v3\"),\n",
    "        (\"Tiny.en   English-only    - faster\", \"tiny.en\"),\n",
    "        (\"Base.en   English-only    - faster\", \"base.en\"),\n",
    "        (\"Small.en  English-only    - faster\", \"small.en\"),\n",
    "        (\"Medium.en English-only    - faster\", \"medium.en\"),\n",
    "        (\"Large.en  English-only    - faster\", \"large-v3.en\")\n",
    "    ]\n",
    "    WHISPER_LANGUAGES = [\n",
    "        (\"English\", \"en\"),\n",
    "        (\"Norwegian\", \"no\"),\n",
    "        (\"Swedish\", \"sv\"),\n",
    "        (\"Danish\", \"da\"),\n",
    "        (\"Finnish\", \"fi\"),\n",
    "        (\"German\", \"de\"),\n",
    "        (\"Dutch\", \"nl\"),\n",
    "        (\"French\", \"fr\"),\n",
    "        (\"Spanish\", \"es\"),\n",
    "        (\"Portuguese\", \"pt\"),\n",
    "        (\"Italian\", \"it\"),\n",
    "        (\"Polish\", \"pl\"),\n",
    "        (\"Czech\", \"cs\"),\n",
    "        (\"Slovak\", \"sk\"),\n",
    "        (\"Hungarian\", \"hu\"),\n",
    "        (\"Greek\", \"el\"),\n",
    "        (\"Turkish\", \"tr\"),\n",
    "        (\"Russian\", \"ru\"),\n",
    "        (\"Ukrainian\", \"uk\"),\n",
    "        (\"Arabic\", \"ar\"),\n",
    "        (\"Hebrew\", \"he\"),\n",
    "        (\"Hindi\", \"hi\"),\n",
    "        (\"Bengali\", \"bn\"),\n",
    "        (\"Urdu\", \"ur\"),\n",
    "        (\"Persian (Farsi)\", \"fa\"),\n",
    "        (\"Thai\", \"th\"),\n",
    "        (\"Vietnamese\", \"vi\"),\n",
    "        (\"Indonesian\", \"id\"),\n",
    "        (\"Malay\", \"ms\"),\n",
    "        (\"Filipino (Tagalog)\", \"tl\"),\n",
    "        (\"Chinese (Mandarin)\", \"zh\"),\n",
    "        (\"Chinese (Cantonese)\", \"yue\"),\n",
    "        (\"Japanese\", \"ja\"),\n",
    "        (\"Korean\", \"ko\"),\n",
    "        (\"Swahili\", \"sw\"),\n",
    "        (\"Afrikaans\", \"af\"),\n",
    "        (\"Romanian\", \"ro\"),\n",
    "        (\"Bulgarian\", \"bg\"),\n",
    "        (\"Serbian\", \"sr\"),\n",
    "        (\"Croatian\", \"hr\"),\n",
    "        (\"Slovenian\", \"sl\"),\n",
    "        (\"Estonian\", \"et\"),\n",
    "        (\"Latvian\", \"lv\"),\n",
    "        (\"Lithuanian\", \"lt\"),\n",
    "    ]\n",
    "\n",
    "    def __init__(self, model, language, transcribe_only):\n",
    "        self.model = model\n",
    "        self.language = language\n",
    "        self.transcribe_only = transcribe_only\n",
    "        super().__init__()\n",
    "\n",
    "    def compose(self) -> ComposeResult:\n",
    "        with Container(id=\"settings-modal\"):\n",
    "            yield Static(\"SETTINGS\", id=\"modal-header\")\n",
    "            yield Rule(line_style=\"heavy\")\n",
    "            with Grid(id=\"settings-grid\"):\n",
    "                yield Static(\"Transcribing model:\", classes=\"select-text\")\n",
    "                yield Select(\n",
    "                        options=self.WHISPER_MODELS,\n",
    "                        allow_blank=False,\n",
    "                        value=self.model,\n",
    "                        id=\"whisper-model\"\n",
    "                )\n",
    "                yield Static(\"Language:\", classes=\"select-text\")\n",
    "                yield Select(\n",
    "                        options=self.WHISPER_LANGUAGES,\n",
    "                        allow_blank=False,\n",
    "                        value=self.language,\n",
    "                        id=\"whisper-language\"\n",
    "                )\n",
    "                yield Static(\"Transcribe only mode:\", classes=\"select-text\")\n",
    "                yield Switch(value=self.transcribe_only,animate=False, id=\"transcribe_only\")\n",
    "                yield Center(\n",
    "                    Button.success(\"Close (esc)\", id=\"save\"),\n",
    "                    id=\"settings-actions\",\n",
    "                )\n",
    "\n",
    "\n",
    "    # Whisper selectors\n",
    "    @on(Select.Changed, \"#whisper-model\")\n",
    "    def on_model_changed(self, event: Select.Changed) -> None:\n",
    "        self.model = str(event.value)\n",
    "\n",
    "    @on(Select.Changed, \"#whisper-language\")\n",
    "    def on_language_changed(self, event: Select.Changed) -> None:\n",
    "        self.language = str(event.value)\n",
    "\n",
    "    @on(Switch.Changed, \"#transcribe_only\")\n",
    "    def on_transcribe_only_changed(self, event: Switch.Changed) -> None:\n",
    "        self.transcribe_only = event.value\n",
    "\n",
    "    def key_escape(self) -> None:\n",
    "        self.dismiss([self.model, self.language, self.transcribe_only])\n",
    "\n",
    "    def on_button_pressed(self) -> None:\n",
    "        self.dismiss([self.model, self.language, self.transcribe_only])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df065f2d",
   "metadata": {},
   "source": [
    "## AI Settings Modal\n",
    "\n",
    "Advanced modal for managing AI models across different providers. Accessed by pressing `a` in the main interface.\n",
    "\n",
    "### Multi-Provider Architecture\n",
    "\n",
    "The modal provides a unified interface for three LLM providers:\n",
    "\n",
    "**OpenAI** - Most popular, wide range of models: <br>\n",
    "- GPT-4o: Latest flagship model, fast and capable <br>\n",
    "- GPT-4o Mini: Smaller, faster, cost-effective variant <br>\n",
    "- GPT-4 Turbo: Previous generation flagship <br>\n",
    "- GPT-4: Original GPT-4 <br>\n",
    "- GPT-3.5 Turbo: Fast and economical <br>\n",
    "\n",
    "**Anthropic** - Claude models known for safety and helpfulness: <br>\n",
    "- Claude 3.5 Sonnet: Latest and most capable <br>\n",
    "- Claude 3 Opus: Powerful reasoning and analysis <br>\n",
    "- Claude 3 Sonnet: Balanced performance <br>\n",
    "- Claude 3 Haiku: Fast and efficient <br>\n",
    "\n",
    "**Google Gemini** - Google's multimodal models: <br>\n",
    "- Gemini 1.5 Pro: Large context window, powerful <br>\n",
    "- Gemini 1.5 Flash: Fast inference, economical <br>\n",
    "- Gemini 1.0 Pro: Previous generation <br>\n",
    "\n",
    "### Dynamic UI Updates\n",
    "\n",
    "When you change providers, the modal: <br>\n",
    "1. Updates the model dropdown with provider-specific options <br>\n",
    "2. Loads any existing API key for that provider (displayed as masked dots) <br>\n",
    "3. Updates the placeholder text in the API key field <br>\n",
    "4. Preserves the last selected model if switching back to a previous provider <br>\n",
    "\n",
    "### API Key Management\n",
    "\n",
    "API keys are: <br>\n",
    "- Stored in XDG-compliant config file at `~/.config/tui_writer/tui_writer.conf` <br>\n",
    "- Displayed as dots for security when present <br>\n",
    "- Only updated if you type a new value (leaving blank keeps existing key) <br>\n",
    "- Loaded into environment variables (`OPENAI_API_KEY`, etc.) when the app starts <br>\n",
    "\n",
    "### Persistence\n",
    "\n",
    "The modal remembers: <br>\n",
    "- Last used provider <br>\n",
    "- Last selected model for each provider <br>\n",
    "- API keys for all providers <br>\n",
    "\n",
    "This allows seamless switching between providers without re-entering credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| include: false\n",
    "\n",
    "PROVIDERS = {\n",
    "    \"openai\": {\n",
    "        \"label\": \"OpenAI\",\n",
    "        \"cfg_key\": \"openai_key\",\n",
    "        \"models\": [\n",
    "            (\"GPT-4o\", \"gpt-4o\"),\n",
    "            (\"GPT-4o Mini\", \"gpt-4o-mini\"),\n",
    "            (\"GPT-4 Turbo\", \"gpt-4-turbo\"),\n",
    "            (\"GPT-4\", \"gpt-4\"),\n",
    "            (\"GPT-3.5 Turbo\", \"gpt-3.5-turbo\"),\n",
    "        ],\n",
    "    },\n",
    "    \"anthropic\": {\n",
    "        \"label\": \"Anthropic\",\n",
    "        \"cfg_key\": \"anthropic_key\",\n",
    "        \"models\": [\n",
    "            (\"Claude 3.5 Sonnet\", \"claude-3-5-sonnet-20241022\"),\n",
    "            (\"Claude 3 Opus\", \"claude-3-opus-20240229\"),\n",
    "            (\"Claude 3 Sonnet\", \"claude-3-sonnet-20240229\"),\n",
    "            (\"Claude 3 Haiku\", \"claude-3-haiku-20240307\"),\n",
    "        ],\n",
    "    },\n",
    "    \"gemini\": {\n",
    "        \"label\": \"Google Gemini\",\n",
    "        \"cfg_key\": \"gemini_key\",\n",
    "        \"models\": [\n",
    "            (\"Gemini 2.5 Pro\", \"gemini-2.5-pro\"),\n",
    "            (\"Gemini 2.5 Flash\", \"gemini-2.5-flash\"),\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "def provider_options():\n",
    "    \"\"\"[(label, value)] for Select.\"\"\"\n",
    "    return [(v[\"label\"], k) for k, v in PROVIDERS.items()]\n",
    "\n",
    "def model_options_for(provider: str):\n",
    "    return PROVIDERS.get(provider, {}).get(\"models\", [])\n",
    "\n",
    "def cfg_key_for(provider: str):\n",
    "    return PROVIDERS.get(provider, {}).get(\"cfg_key\", \"\")\n",
    "\n",
    "def mask_key(key: str) -> str:\n",
    "    return \"â€¢\" * 8 if key else \"\"\n",
    "\n",
    "\n",
    "class AISettingsModal(ModalScreen):\n",
    "    \"\"\"Modal for managing AI model settings across multiple providers.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cfg = get_cfg()\n",
    "\n",
    "        # Resolve defaults from cfg if not provided\n",
    "        self.provider = self.cfg.get(\"last_provider\") or \"openai\"\n",
    "        self.current_model = self.cfg.get(\"last_model\") or \"\"\n",
    "    \n",
    "        # track whether there is an existing key (to keep if input left blank)\n",
    "        self._existing_key = self._read_key(self.provider)\n",
    "\n",
    "    def compose(self) -> ComposeResult:\n",
    "        with Container(id=\"ai-settings-modal\"):\n",
    "            yield Static(\"AI MODEL SETTINGS\", id=\"modal-header\")\n",
    "            yield Rule(line_style=\"heavy\")\n",
    "            \n",
    "            with Grid(id=\"ai-settings-grid\"):\n",
    "                # Provider selection\n",
    "                yield Static(\"AI Provider:\", classes=\"select-text\")\n",
    "                yield Select(\n",
    "                    options=provider_options(),\n",
    "                    allow_blank=False,\n",
    "                    value=self.provider,\n",
    "                    id=\"ai-provider\"\n",
    "                )\n",
    "                \n",
    "                # Model selection\n",
    "                yield Static(\"Model:\", classes=\"select-text\")\n",
    "                yield Select(\n",
    "                    options=model_options_for(self.provider),\n",
    "                    allow_blank=False,\n",
    "                    value=self._initial_model_value(),\n",
    "                    id=\"ai-model\"\n",
    "                )\n",
    "                \n",
    "                # API Key input\n",
    "                yield Static(\"API key:\", classes=\"select-text\")\n",
    "                yield Input(\n",
    "                    placeholder=f\"Enter {PROVIDERS[self.provider]['label']} API keyâ€¦\",\n",
    "                    value=mask_key(self._existing_key),\n",
    "                    id=\"api-key-input\"\n",
    "                )\n",
    "            \n",
    "            with Center():\n",
    "                yield HorizontalGroup(\n",
    "                    Button(\"Apply\", id=\"apply-ai-settings\", variant=\"success\"),\n",
    "                    Button(\"Cancel (esc)\", id=\"cancel-ai-settings\", variant=\"default\"),\n",
    "                    id=\"ai-settings-actions\"\n",
    "                )\n",
    "\n",
    "    def on_mount(self) -> None:\n",
    "        self.provider_select = self.query_one(\"#ai-provider\", Select)\n",
    "        self.model_select = self.query_one(\"#ai-model\", Select)\n",
    "        self.key_input = self.query_one(\"#api-key-input\", Input)\n",
    "\n",
    "    def _initial_model_value(self) -> str:\n",
    "        \"\"\"Pick a valid initial model for the current provider.\"\"\"\n",
    "        opts = model_options_for(self.provider)\n",
    "        values = {v for _, v in opts}\n",
    "        if self.current_model in values:\n",
    "            return self.current_model\n",
    "        return opts[0][1] if opts else \"\"\n",
    "\n",
    "    def _read_key(self, provider: str) -> str:\n",
    "        return self.cfg.get(cfg_key_for(provider)) or \"\"\n",
    "\n",
    "    def _write_key_if_changed(self, provider: str, typed_value: str):\n",
    "        \"\"\"\n",
    "        If user typed a new key (non-empty and not just mask), save it.\n",
    "        If left blank or mask, keep existing.\n",
    "        \"\"\"\n",
    "        if not typed_value or typed_value == mask_key(\"x\"):\n",
    "            return  # keep existing\n",
    "        self.cfg[cfg_key_for(provider)] = typed_value\n",
    "\n",
    "    @on(Select.Changed, \"#ai-provider\")\n",
    "    def on_provider_changed(self, event: Select.Changed) -> None:\n",
    "        new_provider = str(event.value)\n",
    "        if new_provider == self.provider:\n",
    "            return\n",
    "        \n",
    "        # Update state\n",
    "        self.provider = new_provider\n",
    "        self._existing_key = self._read_key(self.provider)\n",
    "        \n",
    "        # Update model list + selection\n",
    "        self.model_select.set_options(model_options_for(self.provider))\n",
    "        self.current_model = self._initial_model_value()\n",
    "        self.model_select.value = self.current_model\n",
    "        \n",
    "        # Update key field (mask if present, else empty placeholder)\n",
    "        self.key_input.value = mask_key(self._existing_key)\n",
    "        self.key_input.placeholder = f\"Enter {PROVIDERS[self.provider]['label']} API keyâ€¦\"\n",
    "\n",
    "    @on(Select.Changed, \"#ai-model\")\n",
    "    def on_model_changed(self, event: Select.Changed) -> None:\n",
    "        if self.current_model == str(event.value):\n",
    "            return\n",
    "        self.current_model = str(event.value)\n",
    "\n",
    "    @on(Button.Pressed, \"#apply-ai-settings\")\n",
    "    def on_apply_settings(self) -> None:\n",
    "        typed = self.key_input.value.strip()\n",
    "\n",
    "        # Save key if user actually typed one\n",
    "        self._write_key_if_changed(self.provider, typed)\n",
    "\n",
    "        # Always persist last used provider/model\n",
    "        self.cfg[\"last_provider\"] = self.provider\n",
    "        self.cfg[\"last_model\"] = self.current_model\n",
    "        self.cfg.save()\n",
    "\n",
    "        self.dismiss(True)\n",
    "\n",
    "    @on(Button.Pressed, \"#cancel-ai-settings\")\n",
    "    def on_cancel_settings(self) -> None:\n",
    "        self.dismiss(None)\n",
    "\n",
    "    def key_escape(self) -> None:\n",
    "        self.dismiss(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319dc553",
   "metadata": {},
   "source": [
    "## HelpModal\n",
    "\n",
    "Interactive help screen accessible by pressing `?` in the main interface. Displays comprehensive documentation using Textual's MarkdownViewer component.\n",
    "\n",
    "### Content Structure\n",
    "\n",
    "The help documentation covers:\n",
    "\n",
    "**Usage Instructions:** <br>\n",
    "- How to start and stop recording <br>\n",
    "- How the AI automatically detects edit commands <br>\n",
    "- Example voice commands for editing <br>\n",
    "\n",
    "**Settings Configuration:** <br>\n",
    "- Audio settings: Model and language selection <br>\n",
    "- AI settings: Provider and model configuration <br>\n",
    "\n",
    "**Keyboard Shortcuts:** <br>\n",
    "- Complete reference table of all available shortcuts <br>\n",
    "- Quick access to common operations <br>\n",
    "\n",
    "### Features\n",
    "\n",
    "- **Markdown Rendering**: Full support for headings, lists, tables, and formatting <br>\n",
    "- **Table of Contents**: Automatic navigation sidebar for long documents <br>\n",
    "- **Scrollable**: Can handle extensive documentation <br>\n",
    "- **Keyboard Dismissal**: Press Esc or click Close button to exit <br>\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The `HELP_MARKDOWN` constant contains the documentation as a multi-line string. The MarkdownViewer widget handles parsing and rendering with syntax highlighting and proper formatting.\n",
    "\n",
    "This approach allows easy updates to documentation without changing code structure - just edit the markdown content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bce9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| include: false\n",
    "\n",
    "HELP_MARKDOWN = \"\"\"\\\n",
    "# TUI Writer\n",
    "\n",
    "Help screen on how to use and customize TUI Writer.\n",
    "\n",
    "## How to use\n",
    "\n",
    "### Live transcriber with AI-powered editing:\n",
    "\n",
    "- Press **SPACE** on your keyboard to start recording (top bar turns red)\n",
    "- Simply start speaking and the transcriber will capture your words\n",
    "- The AI automatically detects when you want to edit previous text\n",
    "- Just say things like:\n",
    "  - \"Actually, change that to...\"\n",
    "  - \"Delete the last sentence\"\n",
    "  - \"Replace pizza with hamburgers\"\n",
    "- The AI will automatically apply edits and update the transcript\n",
    "- Press **SPACE** again to stop recording\n",
    "\n",
    "### Examples of voice commands:\n",
    "\n",
    "**Adding new text:** Just speak normally, the AI will append it.\n",
    "\n",
    "**Editing:** \n",
    "- \"Change the word happy to excited\"\n",
    "- \"Delete that last part\"\n",
    "- \"Replace the first sentence with: Today was great\"\n",
    "\n",
    "## Settings & Configuration\n",
    "\n",
    "### Audio Settings (Press 's'):\n",
    "- Choose Whisper model (tiny to large-v3)\n",
    "- Select transcription language\n",
    "- Faster models = lower accuracy, slower models = better accuracy\n",
    "\n",
    "### AI Model Settings (Press 'a'):\n",
    "- Switch between OpenAI, Anthropic, and Google Gemini\n",
    "- Choose specific models from each provider\n",
    "- Configure API keys securely\n",
    "- All providers work through the same unified interface\n",
    "\n",
    "## Keyboard Shortcuts\n",
    "\n",
    "| Key     | Action                    |\n",
    "|---------|---------------------------|\n",
    "| SPACE   | Start/Stop recording      |\n",
    "| c       | Copy transcript           |\n",
    "| s       | Audio settings            |\n",
    "| a       | AI model settings         |\n",
    "| ?       | This help screen          |\n",
    "| q       | Quit application          |\n",
    "\"\"\"\n",
    "\n",
    "class HelpModal(ModalScreen):\n",
    "    def compose(self) -> ComposeResult:\n",
    "        with Container(id=\"help\"):\n",
    "            markdown_viewer = MarkdownViewer(HELP_MARKDOWN, show_table_of_contents=True)\n",
    "            markdown_viewer.code_indent_guides = False\n",
    "            yield markdown_viewer\n",
    "            yield Center(Button(\"Close (esc)\", variant=\"primary\"))\n",
    "\n",
    "    def on_button_pressed(self) -> None:\n",
    "        self.app.pop_screen()\n",
    "\n",
    "    def key_escape(self) -> None:\n",
    "        self.app.pop_screen()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048cddc",
   "metadata": {},
   "source": [
    "## Transcription TUI\n",
    "\n",
    "The core application that integrates all components into a cohesive user experience.\n",
    "\n",
    "### State Management\n",
    "\n",
    "The application uses a simple state machine with two states:\n",
    "\n",
    "- **IDLE**: Not recording, waiting for user input <br>\n",
    "- **RECORDING**: Active transcription in progress <br>\n",
    "\n",
    "The `state` attribute is reactive, meaning changes automatically trigger UI updates through the `watch_state()` method.\n",
    "\n",
    "### Recording State Indicators\n",
    "\n",
    "**Visual feedback when recording:**\n",
    "- Header background turns red\n",
    "- Title changes to \"â— RECORDING\"\n",
    "- Footer shows recording-specific shortcuts\n",
    "\n",
    "**Visual feedback when idle:**\n",
    "- Header background normal\n",
    "- Title shows \"â—‹ STANDBY (provider/model)\"\n",
    "- Footer shows all available shortcuts\n",
    "\n",
    "### AI Integration Strategy\n",
    "\n",
    "The application maintains a single `TranscriptEditor` instance throughout its lifetime. This is important because:\n",
    "\n",
    "1. **Memory Persistence**: The Chat inside TranscriptEditor maintains a `hist` (history) of all interactions\n",
    "2. **Cross-Session Context**: Even after stopping and restarting recording, the AI remembers previous context\n",
    "3. **Efficient Token Usage**: Conversation history allows contextual edits without re-sending entire transcript\n",
    "4. **Better Edit Detection**: The AI understands references like \"that\" or \"the last part\" from earlier in the session\n",
    "\n",
    "### Transcription Flow\n",
    "\n",
    "1. **User presses SPACE** â†’ `action_toggle_recording()` called\n",
    "2. **State changes to RECORDING** â†’ UI updates via `watch_state()`\n",
    "3. **LiveTranscriber starts** â†’ Begins capturing audio and running VAD\n",
    "4. **Whisper transcribes utterances** â†’ Calls `on_transcript_chunk()` with each result\n",
    "5. **AI processes chunk** â†’ `transcript_editor.process_chunk()` determines action\n",
    "6. **Display updates**:\n",
    "   - For appends: Add new line to Log widget\n",
    "   - For edits: Clear Log and redisplay full transcript\n",
    "7. **User presses SPACE again** â†’ State returns to IDLE, transcriber stops\n",
    "\n",
    "### Callback Pattern\n",
    "\n",
    "The `on_transcript_chunk()` callback demonstrates graceful error handling:\n",
    "\n",
    "```python\n",
    "try:\n",
    "    result = self.transcript_editor.process_chunk(text)\n",
    "    # Update UI based on result\n",
    "except Exception as e:\n",
    "    # Fallback: just append text without AI processing\n",
    "    self.transcript_display.write_line(text)\n",
    "```\n",
    "\n",
    "This ensures transcription continues even if AI processing fails (network issues, API limits, etc.).\n",
    "\n",
    "### Configuration Loading\n",
    "\n",
    "On mount, the application:\n",
    "1. Loads configuration from disk\n",
    "2. Reads API keys for all providers\n",
    "3. Sets environment variables for LLM clients\n",
    "4. Checks if configuration is valid\n",
    "5. Displays appropriate warnings if setup is incomplete\n",
    "\n",
    "### Keyboard Bindings\n",
    "\n",
    "All keyboard shortcuts are declared in the `BINDINGS` class attribute:\n",
    "\n",
    "- **q**: Quit application\n",
    "- **?**: Open help modal\n",
    "- **s**: Open audio settings\n",
    "- **a**: Open AI model settings  \n",
    "- **space**: Toggle recording on/off\n",
    "- **c**: Copy transcript to clipboard\n",
    "\n",
    "Textual automatically displays these in the footer and handles the key events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| include: false\n",
    "\n",
    "# Constants for transcriber configuration\n",
    "DEFAULT_VAD_THRESHOLD = 0.5\n",
    "DEFAULT_MIN_SPEECH_DURATION_MS = 250\n",
    "DEFAULT_MIN_SILENCE_DURATION_MS = 500\n",
    "MIN_EDIT_INSTRUCTION_WORDS = 2\n",
    "\n",
    "class RecordingState(Enum):\n",
    "    \"\"\"High-level states the TUI can be in.\"\"\"\n",
    "    IDLE = auto()       # Not recording\n",
    "    RECORDING = auto()  # Live transcription is running\n",
    "\n",
    "class TranscriptionTUI(App):\n",
    "    \"\"\"Terminal user interface for live audio transcription and AI-powered editing.\n",
    "    \n",
    "    Features:\n",
    "    - Live speech-to-text transcription using Whisper\n",
    "    - AI-powered automatic edit detection and application\n",
    "    - Configurable models and languages\n",
    "    - Copy transcription to clipboard\n",
    "    - AI model management (OpenAI/Anthropic/Gemini)\n",
    "    \"\"\"\n",
    "\n",
    "    # Class attributes\n",
    "    CSS = TEXTUAL_CSS\n",
    "    AUTO_FOCUS = False\n",
    "    state = reactive(RecordingState.IDLE)\n",
    "    BINDINGS = [\n",
    "        (\"q\", \"quit\", \"Quit\"),\n",
    "        (\"?\", \"help_modal\", \"Help\"),\n",
    "        (\"s\", \"settings_modal\", \"Settings\"),\n",
    "        (\"a\", \"ai_settings_modal\", \"AI Models\"),\n",
    "        (\"space\", \"toggle_recording\", \"Start/Stop\"),\n",
    "        (\"c\", \"copy_transcription\", \"Copy transcript\")\n",
    "    ]\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Transcription state\n",
    "        self._transcription_task: asyncio.Task | None = None\n",
    "        self._transcriber: LiveTranscriber | None = None\n",
    "\n",
    "        # Configuration\n",
    "        self.whisper_model = \"base\"\n",
    "        self.language = \"en\"\n",
    "        self.transcribe_only = False\n",
    "        \n",
    "        # AI provider configuration\n",
    "        self.ai_provider = \"\"\n",
    "        self.ai_model = \"\"\n",
    "        \n",
    "        # Initialize transcript editor\n",
    "        self.transcript_editor = None\n",
    "\n",
    "    def compose(self) -> ComposeResult:\n",
    "        \"\"\"Construct and layout all UI widgets.\"\"\"\n",
    "        yield Header(show_clock=True)\n",
    "        yield Log(id=\"transcript-display\", auto_scroll=True)\n",
    "        yield Footer()\n",
    "\n",
    "    def _get_full_model_name(self) -> str:\n",
    "        \"\"\"Get the full model name in lisette format (provider/model).\"\"\"\n",
    "        return f\"{self.ai_provider}/{self.ai_model}\"\n",
    "\n",
    "    # === UI Actions (triggered by key bindings) ===\n",
    "    def action_help_modal(self) -> None:\n",
    "        self.push_screen(HelpModal())\n",
    "\n",
    "    def action_settings_modal(self) -> None:\n",
    "        self.push_screen(SettingsModal(self.whisper_model, self.language, self.transcribe_only), self.apply_settings)\n",
    "\n",
    "    def action_ai_settings_modal(self) -> None:\n",
    "        \"\"\"Open AI model settings modal.\"\"\"\n",
    "        self.push_screen(\n",
    "            AISettingsModal(), \n",
    "            self.apply_ai_settings\n",
    "        ) \n",
    "\n",
    "    async def action_toggle_recording(self) -> None:\n",
    "        \"\"\"Spacebar: start if idle, stop if currently recording.\"\"\"\n",
    "        if self.state is RecordingState.IDLE:\n",
    "            if self.transcribe_only:\n",
    "                await self._start(self.on_transcribe_only)\n",
    "            else:\n",
    "                if not self.ai_model:\n",
    "                    self.notify(\"Please setup AI model first. Press 'a' to set up\", severity=\"warning\")\n",
    "                # Initialize transcript editor if needed\n",
    "                if not self.transcript_editor:\n",
    "                    self.transcript_editor = TranscriptEditor(self._get_full_model_name())\n",
    "                await self._start(self.on_transcript_chunk)\n",
    "\n",
    "            self.state = RecordingState.RECORDING\n",
    "        elif self.state is RecordingState.RECORDING:\n",
    "            self.title = \"STOPPING...\"\n",
    "            await self._stop()\n",
    "            self.state = RecordingState.IDLE\n",
    "\n",
    "    def action_copy_transcription(self) -> None:\n",
    "        if self.transcript_display.line_count > 0:\n",
    "            text = \"\\n\".join(self.transcript_display.lines)\n",
    "            pyperclip.copy(text)\n",
    "            self.notify(\"Copied transcription\", title=\"Copied to clipboard!\")\n",
    "        else:\n",
    "            self.notify(\"Nothing to copy yet!\", severity=\"warning\", title=\"Oops!\")\n",
    "\n",
    "    # === Settings & Modal Callbacks ===\n",
    "    def apply_settings(self, settings: list[str]) -> None:\n",
    "        \"\"\"Apply Whisper model settings.\"\"\"\n",
    "        model, language, transcribe_only = settings\n",
    "        self.whisper_model = model\n",
    "        self.language = language\n",
    "        self.transcribe_only = transcribe_only\n",
    "    \n",
    "    def apply_ai_settings(self, result) -> None:\n",
    "        \"\"\"Apply/update AI provider and model settings.\"\"\"\n",
    "        if result:\n",
    "            self.cfg = get_cfg()\n",
    "            self.load_all_api_keys()\n",
    "            self.ai_provider = self.cfg[\"last_provider\"]\n",
    "            self.ai_model = self.cfg[\"last_model\"]\n",
    "            self.transcript_editor = TranscriptEditor(self._get_full_model_name())\n",
    "            self.notify(\n",
    "                f\"Switched to {self.ai_provider.title()}: {self.ai_model}\", \n",
    "                title=\"AI Provider Updated\"\n",
    "            )\n",
    "            # Update the title to show the new model\n",
    "            if self.state == RecordingState.IDLE:\n",
    "                self.title = f\"â—‹ STANDBY ({self.ai_provider}/{self.ai_model})\"\n",
    "\n",
    "    # === Transcription Lifecycle ===\n",
    "    async def _start(self, on_transcript_callback) -> None:\n",
    "        self._transcriber = LiveTranscriber(\n",
    "            model_id=self.whisper_model,\n",
    "            language=self.language,\n",
    "            on_transcript=on_transcript_callback,\n",
    "            vad_threshold=DEFAULT_VAD_THRESHOLD,\n",
    "            min_speech_duration_ms=DEFAULT_MIN_SPEECH_DURATION_MS,\n",
    "            min_silence_duration_ms=DEFAULT_MIN_SILENCE_DURATION_MS,\n",
    "        )\n",
    "        self._transcription_task = asyncio.create_task(self._transcriber.start())\n",
    "\n",
    "    async def _stop(self) -> None:\n",
    "        try:\n",
    "            if self._transcriber:\n",
    "                await self._transcriber.stop()\n",
    "            if self._transcription_task:\n",
    "                await self._transcription_task\n",
    "        finally:\n",
    "            self._transcriber = None\n",
    "            self._transcription_task = None\n",
    "\n",
    "    # === Event Handlers & Callbacks ===\n",
    "    def _normalize_text(self, text: str) -> str:\n",
    "        \"\"\"Normalize and clean text input.\"\"\"\n",
    "        return (text or \"\").strip()\n",
    "\n",
    "    def on_transcribe_only(self, text: str) -> None:\n",
    "        text = self._normalize_text(text)\n",
    "        if not text:\n",
    "            return\n",
    "        self.transcript_display.write_line(text)\n",
    "\n",
    "\n",
    "    async def on_transcript_chunk(self, text: str) -> None:\n",
    "        \"\"\"Called whenever the transcriber produces a new text chunk.\n",
    "        Passes through AI to detect edits vs new text.\"\"\"\n",
    "        text = self._normalize_text(text)\n",
    "        if not text:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Process chunk through AI\n",
    "            result = await self.transcript_editor.process_chunk(text)\n",
    "            \n",
    "            # Update display based on action\n",
    "            if result[\"action\"] == \"edit\":\n",
    "                # Full transcript was edited - refresh entire display\n",
    "                self.transcript_display.clear()\n",
    "                self.transcript_display.write_lines(result[\"transcript\"].splitlines(True))\n",
    "                self.notify(f\"âœï¸ Edit detected (tokens: {result['tokens_used']})\", timeout=2)\n",
    "            else:\n",
    "                # New text appended - just add the line\n",
    "                self.transcript_display.write_line(text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback: just append the text without AI processing\n",
    "            self.notify(f\"AI processing failed: {str(e)}\", severity=\"error\", timeout=3)\n",
    "            self.transcript_display.write_line(text)\n",
    "\n",
    "    def watch_state(self, new_state: RecordingState) -> None:\n",
    "        \"\"\"Reactively update UI when recording state changes.\"\"\"\n",
    "        self.sub_title = \"\"\n",
    "\n",
    "        match new_state:\n",
    "            case RecordingState.IDLE:\n",
    "                self.title = f\"â—‹ STANDBY ({self.ai_provider}/{self.ai_model})\"\n",
    "                self.header.remove_class(\"recording\")\n",
    "            case RecordingState.RECORDING:\n",
    "                self.title = \"â— RECORDING\"\n",
    "                self.header.add_class(\"recording\")\n",
    "\n",
    "    def load_all_api_keys(self) -> None:\n",
    "        if self.cfg.get(\"openai_key\"):\n",
    "            os.environ[\"OPENAI_API_KEY\"] = self.cfg[\"openai_key\"]\n",
    "        \n",
    "        if self.cfg.get(\"anthropic_key\"):\n",
    "            os.environ[\"ANTHROPIC_API_KEY\"] = self.cfg[\"anthropic_key\"]\n",
    "\n",
    "        if self.cfg.get(\"gemini_key\"):\n",
    "            os.environ[\"GEMINI_API_KEY\"] = self.cfg[\"gemini_key\"]\n",
    "\n",
    "    # === Lifecycle Hooks ===\n",
    "    def on_mount(self) -> None:\n",
    "        \"\"\"Initialize widget references and set titles.\"\"\"\n",
    "        self.cfg = get_cfg()\n",
    "        self.load_all_api_keys()\n",
    "        if self.cfg[\"last_provider\"] and self.cfg[\"last_model\"]:\n",
    "            self.ai_provider = self.cfg[\"last_provider\"]\n",
    "            self.ai_model = self.cfg[\"last_model\"]\n",
    "\n",
    "        # Check if provider is configured\n",
    "        if not self.ai_provider:\n",
    "            self.notify(\"No AI provider configured, press 'a' to set up.\", severity=\"error\")\n",
    "            self.title = \"â—‹ STANDBY (No Provider Configured)\"\n",
    "        elif not self.cfg[f\"{self.ai_provider}_key\"]:\n",
    "            self.notify(\"No API key recognized, press 'a' to set up.\", severity=\"error\")\n",
    "            self.title = f\"â—‹ STANDBY ({self.ai_provider}/{self.ai_model})\"\n",
    "        else:\n",
    "            self.notify(f\"Using: {self.ai_provider} & {self.ai_model}. Loaded API Key successfully\")\n",
    "            self.title = f\"â—‹ STANDBY ({self.ai_provider}/{self.ai_model})\"\n",
    "\n",
    "        self.header = self.query_one(Header)\n",
    "        self.transcript_display: Log = self.query_one(\"#transcript-display\", Log)\n",
    "        self.theme = \"textual-dark\"\n",
    "\n",
    "    async def on_unmount(self) -> None:\n",
    "        await self._stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
