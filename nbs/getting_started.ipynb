{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUI Writer\n",
    "\n",
    "> A TUI that you run to transcribe and edit text. It's like a companion that dictates for you, engaging in a dialogue to collaboratively update a block of text rather than performing a direct transcription.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are new to using `nbdev` here are some useful pointers to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install tui_writer in Development mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# make sure tui_writer package is installed in development mode\n",
    "$ pip install -e .\n",
    "\n",
    "# make changes under nbs/ directory\n",
    "# ...\n",
    "\n",
    "# compile to have changes apply to tui_writer\n",
    "$ nbdev_prepare\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install latest from the GitHub [repository][repo]:\n",
    "\n",
    "```sh\n",
    "$ pip install git+https://github.com/Swiftner/tui_writer.git\n",
    "```\n",
    "\n",
    "or from [conda][conda]\n",
    "\n",
    "```sh\n",
    "$ conda install -c Swiftner tui_writer\n",
    "```\n",
    "\n",
    "or from [pypi][pypi]\n",
    "\n",
    "\n",
    "```sh\n",
    "$ pip install tui_writer\n",
    "```\n",
    "\n",
    "\n",
    "[repo]: https://github.com/Swiftner/tui_writer\n",
    "[docs]: https://Swiftner.github.io/tui_writer/\n",
    "[pypi]: https://pypi.org/project/tui_writer/\n",
    "[conda]: https://anaconda.org/Swiftner/tui_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation can be found hosted on this GitHub [repository][repo]'s [pages][docs]. Additionally you can find package manager specific guidelines on [conda][conda] and [pypi][pypi] respectively.\n",
    "\n",
    "[repo]: https://github.com/Swiftner/tui_writer\n",
    "[docs]: https://Swiftner.github.io/tui_writer/\n",
    "[pypi]: https://pypi.org/project/tui_writer/\n",
    "[conda]: https://anaconda.org/Swiftner/tui_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development Plan: Real-Time Transcription with LLM Integration\n",
    "\n",
    "### Current State\n",
    "TUI Writer currently supports basic live transcription using FastRTC with speech-to-text models. The system can detect pauses and transcribe audio in real-time, but lacks LLM integration for intelligent text processing and iterative refinement.\n",
    "\n",
    "### Development Philosophy: MVP-First Approach\n",
    "**Focus on understanding and user experience over raw speed. Build a great Minimum Viable Product that demonstrates the core concept of AI-assisted writing through natural conversation patterns.**\n",
    "\n",
    "### Core MVP Goal\n",
    "**Create a TUI where users can speak naturally, see their words transcribed in real-time, and engage in a conversation with an LLM that helps refine and improve their text collaboratively.**\n",
    "\n",
    "### Key Features to Implement\n",
    "\n",
    "#### Phase 1: Core TUI Transcription Experience\n",
    "- [ ] Create intuitive TUI layout showing live transcription\n",
    "- [ ] Implement basic pause detection for natural speech flow\n",
    "- [ ] Add simple text buffer that accumulates speech\n",
    "- [ ] Show clear visual feedback during transcription\n",
    "\n",
    "#### Phase 2: LLM Integration & Conversation\n",
    "- [ ] Connect LLM to transcribed text for intelligent suggestions\n",
    "- [ ] Implement conversation context that remembers previous exchanges\n",
    "- [ ] Create natural language prompts for text improvement\n",
    "- [ ] Add simple suggestion display in TUI\n",
    "\n",
    "#### Phase 3: Interactive Text Refinement\n",
    "- [ ] Build text editing workflow (accept/modify/discard suggestions)\n",
    "- [ ] Implement iterative refinement - speak more, get better suggestions\n",
    "- [ ] Add conversation memory for context-aware improvements\n",
    "- [ ] Create intuitive keyboard shortcuts for text management\n",
    "\n",
    "#### Phase 4: Polish & User Experience\n",
    "- [ ] Add helpful onboarding and usage instructions\n",
    "- [ ] Implement error handling and recovery\n",
    "- [ ] Add configuration options for different use cases\n",
    "- [ ] Create demo modes and examples\n",
    "\n",
    "### Technical Architecture\n",
    "\n",
    "#### Core Components\n",
    "```\n",
    "┌─────────────────┐    ┌─────────────────────────────────────┐    ┌─────────────────┐\n",
    "│     Audio       │───▶│         FastRTC +                   │───▶│      LLM        │\n",
    "│     Input       │    │     Pause Detector                  │    │   Processing    │\n",
    "└─────────────────┘    │                                     │    └─────────────────┘\n",
    "                       │   ┌─────────────────────────────────┐ │              │\n",
    "                       │   │       Transcribes               │ │              │\n",
    "                       │   │       in Chunks                 │ │              │\n",
    "                       │   └─────────────────────────────────┘ │              │\n",
    "                       └─────────────────────────────────────┘              │\n",
    "                                                                            │\n",
    "┌─────────────────┐                                                         │\n",
    "│   Text Block    │◀──────────────────────────────────────────────────────────┘\n",
    "│   Management    │\n",
    "└─────────────────┘\n",
    "```\n",
    "\n",
    "#### Data Flow\n",
    "1. **Audio Capture** → FastRTC streams continuous audio input\n",
    "2. **Real-time Processing** → Pause Detector identifies speech segments and silence gaps\n",
    "3. **Chunked Transcription** → Audio transcribed in manageable chunks during/after speech\n",
    "4. **LLM Integration** → Each transcribed chunk sent to LLM for intelligent processing\n",
    "5. **Text Block Updates** → LLM-refined text updates the main text buffer\n",
    "6. **Continuous Loop** → Process repeats with each new speech chunk for iterative refinement\n",
    "\n",
    "### Integration Points\n",
    "\n",
    "#### With Existing TUI Writer Components\n",
    "- **CLI Module**: Add real-time transcription commands\n",
    "- **AI Module**: Extend for LLM integration\n",
    "- **Live Module**: Enhance current FastRTC implementation\n",
    "\n",
    "#### External Dependencies\n",
    "- **fastrtc**: Real-time audio streaming\n",
    "- **faster_whisper**: Fast speech-to-text\n",
    "- **openai/smolagents**: LLM integration\n",
    "- **rich**: Enhanced terminal UI for text display\n",
    "\n",
    "### Testing Strategy\n",
    "\n",
    "#### Unit Tests\n",
    "- [ ] Audio processing pipeline tests\n",
    "- [ ] LLM integration mocking\n",
    "- [ ] Text merge/diff algorithms\n",
    "\n",
    "#### Integration Tests\n",
    "- [ ] End-to-end transcription workflow\n",
    "- [ ] Multi-provider LLM testing\n",
    "- [ ] Performance benchmarking\n",
    "\n",
    "#### User Experience Tests\n",
    "- [ ] Real-time responsiveness validation\n",
    "- [ ] Text quality assessment\n",
    "- [ ] Error handling verification\n",
    "\n",
    "### Success Metrics\n",
    "\n",
    "#### MVP Quality Targets\n",
    "- **Natural Conversation Flow**: Users can speak naturally without timing pressures\n",
    "- **Clear Transcription Display**: Text appears in real-time as user speaks\n",
    "- **Helpful LLM Suggestions**: AI provides meaningful improvements to text\n",
    "- **Intuitive TUI Experience**: Users understand how to interact with the system\n",
    "\n",
    "#### User Experience Focus\n",
    "- **Forgiving Interaction**: Works well even with imperfect speech or pauses\n",
    "- **Clear Feedback**: Users always know what's happening (transcribing, processing, ready)\n",
    "- **Helpful Guidance**: System suggests improvements without being overwhelming\n",
    "- **Easy Text Management**: Simple commands to accept, edit, or discard suggestions\n",
    "\n",
    "### Getting Started with Development\n",
    "\n",
    "#### Prerequisites\n",
    "```bash\n",
    "# Install development dependencies\n",
    "uv add --dev jupyterlab ipykernel\n",
    "\n",
    "# Install project in development mode\n",
    "uv sync\n",
    "\n",
    "# Run Jupyter Lab for development\n",
    "uv run jupyter lab\n",
    "```\n",
    "\n",
    "#### Development Workflow\n",
    "1. **Start with live transcription** (`nbs/02_live.ipynb`)\n",
    "2. **Enhance pause detection** for better triggering\n",
    "3. **Add LLM integration** to existing transcription pipeline\n",
    "4. **Test iteratively** with real audio input\n",
    "5. **Refine UI/UX** based on testing feedback\n",
    "\n",
    "#### Key Files to Modify\n",
    "- `nbs/02_live.ipynb` - Core real-time transcription logic\n",
    "- `nbs/01_ai.ipynb` - LLM integration and text processing\n",
    "- `nbs/00_cli.ipynb` - Command-line interface updates\n",
    "- `tui_writer/cli.py` - Main application entry point\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Review current live transcription implementation**\n",
    "2. **Identify specific areas for LLM integration**\n",
    "3. **Start with simple text refinement after pauses**\n",
    "4. **Iteratively add more sophisticated features**\n",
    "\n",
    "This development plan provides a structured approach to building an intelligent real-time transcription system with LLM-powered text refinement, transforming TUI Writer into a powerful collaborative writing tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill me in please! Don't forget code examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Transcription with FastRTC\n",
    "\n",
    "TUI Writer supports live transcription functionality through [FastRTC](https://fastrtc.org/userguide/audio/), a powerful real-time audio streaming library. This enables real-time speech-to-text capabilities with advanced features like pause detection, interrupt handling, and telephone integration.\n",
    "\n",
    "#### Adding Live Transcription\n",
    "\n",
    "To add live transcription capabilities using FastRTC:\n",
    "\n",
    "1. **Install FastRTC with audio dependencies:**\n",
    "```bash\n",
    "pip install fastrtc[stt,tts]\n",
    "```\n",
    "\n",
    "2. **Basic live transcription setup:**\n",
    "```python\n",
    "from fastrtc import Stream, ReplyOnPause, get_stt_model\n",
    "import numpy as np\n",
    "\n",
    "# Initialize speech-to-text model\n",
    "stt_model = get_stt_model(model=\"moonshine/base\")\n",
    "\n",
    "def live_transcribe(audio: tuple[int, np.ndarray]) -> str:\n",
    "    \"\"\"Process live audio and return transcription\"\"\"\n",
    "    sample_rate, audio_array = audio\n",
    "    return stt_model.stt(audio)\n",
    "\n",
    "# Create FastRTC stream with live transcription\n",
    "stream = Stream(\n",
    "    handler=ReplyOnPause(live_transcribe),\n",
    "    modality=\"audio\",\n",
    "    mode=\"send-receive\"\n",
    ")\n",
    "\n",
    "# Mount to your FastAPI app\n",
    "# stream.mount(app)\n",
    "```\n",
    "\n",
    "3. **Advanced configuration with pause detection:**\n",
    "```python\n",
    "from fastrtc import Stream, ReplyOnPause, AlgoOptions, SileroVadOptions\n",
    "\n",
    "def enhanced_transcribe(audio: tuple[int, np.ndarray]) -> str:\n",
    "    \"\"\"Enhanced transcription with better pause detection\"\"\"\n",
    "    sample_rate, audio_array = audio\n",
    "    return stt_model.stt(audio)\n",
    "\n",
    "stream = Stream(\n",
    "    handler=ReplyOnPause(\n",
    "        enhanced_transcribe,\n",
    "        algo_options=AlgoOptions(\n",
    "            audio_chunk_duration=0.6,\n",
    "            started_talking_threshold=0.2,\n",
    "            speech_threshold=0.1\n",
    "        ),\n",
    "        model_options=SileroVadOptions(\n",
    "            threshold=0.5,\n",
    "            min_speech_duration_ms=250,\n",
    "            min_silence_duration_ms=100\n",
    "        )\n",
    "    ),\n",
    "    modality=\"audio\",\n",
    "    mode=\"send-receive\"\n",
    ")\n",
    "```\n",
    "\n",
    "#### Key Features\n",
    "\n",
    "- **Real-time processing**: Audio is processed as you speak\n",
    "- **Pause detection**: Automatically detects when you stop speaking\n",
    "- **Interrupt handling**: Can be interrupted by speaking again\n",
    "- **Telephone integration**: Works with SIP providers like Twilio\n",
    "- **Customizable voice activity detection**: Fine-tune sensitivity and timing\n",
    "\n",
    "#### Integration with TUI Writer\n",
    "\n",
    "The live transcription functionality integrates seamlessly with TUI Writer's existing text editing capabilities, allowing you to:\n",
    "- Transcribe speech in real-time\n",
    "- Edit transcribed text interactively\n",
    "- Use voice commands for text manipulation\n",
    "- Maintain conversation history for context\n",
    "\n",
    "For more detailed examples and advanced configurations, see the [FastRTC Audio Streaming Guide](https://fastrtc.org/userguide/audio/).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
