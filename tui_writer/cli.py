# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_cli.ipynb.

# %% auto 0
__all__ = ['console', 'app', 'format_duration', 'copy_to_clipboard', 'TranscriptionTUI', 'ModelsScreen', 'hello', 'tui',
           'transcribe_last']

# %% ../nbs/00_cli.ipynb 4
import os
import sys
import threading
import time
import wave
from pathlib import Path
from typing import Optional, Union

import pyperclip
import typer
from rich.console import Console
from textual.app import App, ComposeResult
from textual.containers import Horizontal, Vertical
from textual.screen import ModalScreen
from textual.widgets import Button, DataTable, Footer, Header, Static, TextArea
from .transcription import WhisperTranscriber

from .audio import AudioRecorder

# Console for rich formatting
console = Console()

def _is_cuda_available() -> bool:
    """Check if CUDA is available for GPU acceleration."""
    try:
        import torch
        return torch.cuda.is_available()
    except ImportError:
        return False

# %% ../nbs/00_cli.ipynb 5
def format_duration(seconds: float) -> str:
    """Format duration in seconds to HH:MM:SS or MM:SS format."""
    total_seconds = int(seconds)
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    secs = total_seconds % 60

    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes:02d}:{secs:02d}"


# %% ../nbs/00_cli.ipynb 12
def copy_to_clipboard(text: str, elapsed_time: Optional[float] = None):
    """Copy transcribed text to system clipboard and display results.

    This function serves as the final step in the transcription pipeline,
    making the results immediately accessible to the user through multiple
    channels: system clipboard for easy pasting, and visual confirmation
    in the terminal interface.

    Args:
        text: The transcribed text content to copy
        elapsed_time: Optional processing time for performance feedback

    The function provides immediate visual feedback about the transcription
    success and performance metrics, ensuring users understand both the
    result quality and system performance.
    """
    pyperclip.copy(text)
    if elapsed_time:
        console.print(f"âœ… [bold green]Transcribed and copied to clipboard in {elapsed_time:.1f}s![/bold green]")
    else:
        console.print("âœ… [bold green]Transcribed and copied to clipboard![/bold green]")
    console.print(f"\n{text}")        

# %% ../nbs/00_cli.ipynb 14
class TranscriptionTUI(App):
    """Interactive terminal user interface for audio transcription.

    This class implements a comprehensive terminal-based user interface using
    the Textual framework. It coordinates all aspects of the transcription
    workflow while providing an intuitive and responsive user experience.

    The TUI manages the complete user journey from initial launch through
    audio recording, AI processing, and result presentation. It handles
    state management, user input, progress feedback, and error conditions
    in a unified interface.

    Key Features:
        - Real-time recording status with live timer
        - Interactive model selection via modal dialogs
        - Immediate visual feedback for all operations
        - Keyboard shortcuts for efficient workflow
        - Automatic clipboard integration for results
        - Cross-platform terminal compatibility

    The interface is designed to be both powerful for advanced users and
    approachable for newcomers to speech transcription technology.
    """

    CSS = """
    /* Comprehensive styling for the transcription TUI

    This stylesheet defines the visual appearance and layout of all interface
    components. The design emphasizes clarity, accessibility, and visual
    hierarchy while maintaining terminal compatibility across different
    terminal emulators and color schemes.

    Color Scheme:
    - Primary colors for interactive elements
    - Success colors for positive feedback
    - Warning colors for active operations
    - Error colors for problem indication
    - Muted colors for secondary information

    Layout Strategy:
    - Vertical stacking for logical information flow
    - Responsive sizing for different terminal dimensions
    - Consistent spacing and visual rhythm
    - Clear component boundaries and grouping
    */
    Screen {
        layout: vertical;
    }

    #status {
        height: 3;
        margin: 1;
    }

    #recording-display {
        height: 3;
        margin: 1;
        text-align: center;
    }

    #transcription-display {
        height: 1fr;
        margin: 1;
        border: solid $primary;
        padding: 1;
    }

    #controls {
        height: 3;
        margin: 1;
    }

    Button {
        margin: 0 1;
    }

    .recording {
        color: red;
        text-style: bold;
    }

    .transcribing {
        color: blue;
        text-style: bold;
    }

    .success {
        color: green;
        text-style: bold;
    }

    .error {
        color: red;
        text-style: bold;
    }

    /* Modal screen styling */
    ModelsScreen {
        align: center middle;
    }

    #models-container {
        width: 80;
        height: 70%;
        border: solid $primary;
        background: $surface;
        padding: 1;
    }

    #models-title {
        text-align: center;
        margin-bottom: 1;
    }

    #models-subtitle {
        text-align: center;
        margin-bottom: 1;
        color: $text-muted;
    }

    #models-table {
        height: 1fr;
    }

    #models-buttons {
        margin-top: 1;
        align: center middle;
    }
    """

    BINDINGS = [
        ("r", "start_recording", "Start Recording"),
        ("s", "stop_recording", "Stop Recording"),
        ("t", "transcribe_last", "Transcribe Last Recording"),
        ("l", "list_models", "List Models"),
        ("q", "quit", "Quit"),
        ("c", "copy_to_clipboard", "Copy to Clipboard"),
        ("enter", "stop_and_transcribe", "Stop Recording & Transcribe"),
    ]

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.recorder = AudioRecorder()
        self.transcriber = WhisperTranscriber()
        self.recording_timer = None
        self.recording_start_time = None
        self.current_transcription = None

    def compose(self) -> ComposeResult:
        """Define the user interface layout and component hierarchy.

        This method implements the structural composition of the TUI, arranging
        all visual components in a logical hierarchy that supports the user's
        workflow. The layout follows a vertical stacking pattern that guides
        the user's attention from top to bottom through the transcription process.

        Layout Components (Top to Bottom):
        1. Header - Application branding and navigation
        2. Title - Clear identification of current context
        3. Status Display - Real-time operation feedback
        4. Recording Indicator - Live recording state and timer
        5. Transcription Area - Large text area for result display
        6. Control Panel - Primary action buttons
        7. Footer - Keyboard shortcuts and help

        Each component serves a specific role in the user experience while
        maintaining visual consistency and functional clarity.
        """
        yield Header()
        yield Vertical(
            Static("ðŸŽ¤ Audio Transcription TUI", id="title", classes="success"),
            Static("", id="status"),
            Static("", id="recording-display"),
            TextArea("Transcription will appear here...", id="transcription-display", disabled=True),
            Horizontal(
                Button("ðŸŽ¤ Recording... (ENTER to stop & transcribe)", variant="warning", id="recording-status", disabled=True),
                Button("Stop Recording (S)", variant="error", id="stop-btn", disabled=True),
                Button("Transcribe Last (T)", variant="primary", id="transcribe-btn"),
                Button("List Models (L)", variant="default", id="models-btn"),
                Button("Quit (Q)", variant="default", id="quit-btn"),
                id="controls"
            ),
            id="main-container"
        )
        yield Footer()

    def on_mount(self) -> None:
        """Initialize the application and begin the transcription workflow.

        This lifecycle method is called when the TUI application starts up.
        It performs essential initialization tasks and immediately begins the
        recording process, providing users with an instant, streamlined experience.

        Initialization Sequence:
        1. Set initial status message welcoming the user
        2. Validate system readiness for audio recording
        3. Initialize the audio recording subsystem
        4. Start real-time recording with visual feedback

        The method ensures the application is immediately functional and
        provides clear feedback about its operational state.
        """
        # Start recording immediately for streamlined user experience
        self.start_recording()

    def on_button_pressed(self, event: Button.Pressed) -> None:
        """Handle button presses."""
        button_id = event.button.id
        if button_id == "start-btn":
            self.start_recording()
        elif button_id == "stop-btn":
            self.stop_recording()
        elif button_id == "recording-status":
            self.action_stop_and_transcribe()
        elif button_id == "transcribe-btn":
            self.transcribe_last()
        elif button_id == "models-btn":
            self.list_models()
        elif button_id == "quit-btn":
            self.quit()

    def action_start_recording(self) -> None:
        """Start audio recording."""
        self.start_recording()

    def action_stop_recording(self) -> None:
        """Stop audio recording."""
        self.stop_recording()

    def action_transcribe_last(self) -> None:
        """Transcribe the last recorded audio."""
        self.transcribe_last()

    def action_list_models(self) -> None:
        """List available Whisper models."""
        self.list_models()

    def action_quit(self) -> None:
        """Quit the application."""
        self.exit()

    def action_copy_to_clipboard(self) -> None:
        """Copy current transcription to clipboard."""
        if self.current_transcription:
            copy_to_clipboard(self.current_transcription)
            self.update_status("Transcription copied to clipboard!")
        else:
            self.update_status("No transcription to copy!")

    def action_stop_and_transcribe(self) -> None:
        """Stop recording and transcribe the audio."""
        if self.recorder.recording:
            self.stop_recording()
            # Start transcription immediately after stopping recording
            self.call_later(self.transcribe_last)

    def start_recording(self) -> None:
        """Initiate audio recording with comprehensive setup and feedback.

        This method orchestrates the complete recording initialization process,
        ensuring all subsystems are properly configured before audio capture begins.
        It provides immediate visual feedback and handles potential errors gracefully.

        Recording Setup Process:
        1. Validate audio input device availability
        2. Initialize WAV file for audio storage
        3. Configure audio stream parameters
        4. Start background recording with real-time feedback
        5. Update interface to reflect recording state
        6. Initialize progress timer for user feedback

        The method ensures robust error handling and provides clear status
        updates throughout the recording lifecycle.
        """
        try:
            self.recorder.start_recording()
            self.recording_start_time = time.time()
            self.update_status("ðŸ”´ Recording started...")
            self.update_recording_display("Recording... 00:00")

            # Update recording timer
            self.recording_timer = self.set_interval(1.0, self.update_recording_timer)

            # Update button states
            self.query_one("#stop-btn", Button).disabled = False

        except Exception as e:
            self.update_status(f"âŒ Failed to start recording: {e}", "error")

    def stop_recording(self) -> None:
        """Stop the recording process."""
        if self.recording_timer:
            self.recording_timer.stop()
            self.recording_timer = None

        try:
            self.recorder.stop_recording()
            elapsed = time.time() - self.recording_start_time
            duration_str = format_duration(elapsed)

            self.update_status(f"âœ… Recording stopped. Duration: {duration_str}")
            self.update_recording_display(f"Recording saved: {duration_str}")

            # Update button states
            self.query_one("#stop-btn", Button).disabled = True

        except Exception as e:
            self.update_status(f"âŒ Failed to stop recording: {e}", "error")

    def transcribe_last(self) -> None:
        """Transcribe the last recorded audio file."""
        audio_path = self.recorder.audio_file_path

        if not audio_path.exists():
            self.update_status("âŒ No previous recording found. Record audio first.", "error")
            return

        # Update UI state
        self.update_status("ðŸ”„ Transcribing audio...")
        self.query_one("#transcribe-btn", Button).disabled = True

        # Run transcription in a separate thread to avoid blocking the UI
        def do_transcription():
            try:
                transcription, elapsed_time = self.transcriber.transcribe(audio_path)

                # Update UI from the main thread
                self.call_from_thread(
                    self.transcription_complete, transcription, elapsed_time
                )
            except Exception as e:
                self.call_from_thread(
                    self.update_status, f"âŒ Transcription failed: {e}", "error"
                )
                def reset_transcribe_button():
                    self.query_one("#transcribe-btn", Button).update("Transcribe Last (T)")
                    self.query_one("#transcribe-btn", Button).disabled = False

                self.call_from_thread(reset_transcribe_button)

        threading.Thread(target=do_transcription, daemon=True).start()

    def transcription_complete(self, transcription: str, elapsed_time: float) -> None:
        """Called when transcription is complete."""
        self.current_transcription = transcription
        self.query_one("#transcription-display", TextArea).text = transcription
        self.query_one("#transcribe-btn", Button).disabled = False

        copy_to_clipboard(transcription, elapsed_time)
        self.update_status(f"âœ… Transcription completed in {elapsed_time:.1f}s")

    def list_models(self) -> None:
        """Display comprehensive model selection interface.

        Opens an interactive modal dialog that presents all available Whisper
        models with detailed information about their capabilities, performance
        characteristics, and recommended use cases. This interface allows users
        to make informed decisions about model selection based on their specific
        requirements.

        Modal Features:
        - Complete model catalog with categorization
        - Performance metrics and size information
        - Current model highlighting
        - Interactive selection with visual feedback
        - Real-time model switching capability

        The modal integrates seamlessly with the main interface, providing
        both informational and functional capabilities in a single interaction.
        """
        # Launch modal with current transcriber for context
        self.app.push_screen(ModelsScreen(transcriber=self.transcriber))

    def update_status(self, message: str, style: str = "default") -> None:
        """Update the status display."""
        try:
            status_widget = self.query_one("#status", Static)
            status_widget.update(message)
            if style == "error":
                status_widget.add_class("error")
            elif style == "success":
                status_widget.add_class("success")
            else:
                status_widget.remove_class("error success")
        except Exception:
            # Widget might not be available yet during initialization
            pass

    def update_recording_display(self, message: str) -> None:
        """Update the recording display and status button."""
        try:
            display_widget = self.query_one("#recording-display", Static)
            display_widget.update(message)

            # Also update the recording status button
            status_button = self.query_one("#recording-status", Button)
            if "Recording" in message:
                status_button.label = f"ðŸŽ¤ {message} (ENTER to stop & transcribe)"
                status_button.variant = "warning"
            else:
                status_button.label = "âœ… Ready to record"
                status_button.variant = "success"
        except Exception:
            # Widget might not be available yet during initialization
            pass

    def update_recording_timer(self) -> None:
        """Update the recording timer display."""
        if self.recording_start_time:
            elapsed = time.time() - self.recording_start_time
            time_str = format_duration(elapsed)
            self.update_recording_display(f"ðŸ”´ Recording... {time_str}")

# %% ../nbs/00_cli.ipynb 15
# ## Model Selection Interface
#
# The ModelsScreen class implements an advanced modal dialog for Whisper model selection. This component provides users with comprehensive information about available models and enables intelligent model switching based on their specific requirements and system capabilities.

class ModelsScreen(ModalScreen):
    """Interactive modal interface for Whisper model selection and management.

    This modal screen provides a comprehensive interface for users to explore,
    compare, and select from all available Whisper models. It presents models
    in an organized table format with detailed specifications and enables
    real-time model switching with immediate feedback.

    Key Capabilities:
        - Complete model catalog with 19+ models
        - Categorized display (English-only, Multilingual, Distilled, Turbo)
        - Performance metrics and size information
        - Current model highlighting and status
        - Interactive selection with keyboard navigation
        - Real-time model switching and validation

    The interface is designed to be both informative for model selection
    and functional for immediate model changes, providing users with
    complete control over their transcription configuration.
    """

    def __init__(self, transcriber=None, **kwargs):
        super().__init__(**kwargs)
        self.models = WhisperTranscriber.VALID_MODELS
        self.transcriber = transcriber
        self.selected_row = 0

    def compose(self) -> ComposeResult:
        current_model = self.transcriber.model_name if self.transcriber else "None"
        yield Header()
        yield Vertical(
            Static("ðŸŽ¯ Available Whisper Models", id="models-title", classes="success"),
            Static(f"Current model: [bold cyan]{current_model}[/bold cyan]", id="current-model"),
            Static("Select a model for transcription (use â†‘â†“ arrows, then click Select):", id="models-subtitle"),
            DataTable(id="models-table", cursor_type="row"),
            Horizontal(
                Button("Select Model", variant="success", id="select-btn"),
                Button("Close", variant="default", id="close-btn"),
                id="models-buttons"
            ),
            id="models-container"
        )
        yield Footer()

    def on_mount(self) -> None:
        """Set up the models table when the screen mounts."""
        table = self.query_one("#models-table", DataTable)

        # Add columns
        table.add_columns("Model Name", "Type", "Description")

        # Add model data
        current_model = self.transcriber.model_name if self.transcriber else None
        for i, model in enumerate(self.models):
            # Categorize models
            if model.endswith(".en"):
                model_type = "English-only"
                description = "Optimized for English speech"
            elif model.startswith("distil-"):
                model_type = "Distilled"
                description = "Faster, smaller version"
            elif "turbo" in model:
                model_type = "Turbo"
                description = "Fastest performance"
            else:
                model_type = "Multilingual"
                description = "Supports multiple languages"

            # Mark current model with indicator
            if model == current_model:
                model = f"â–¶ {model}"  # Add arrow indicator for current model

            table.add_row(model, model_type, description)

        # Set cursor to current model if found
        if current_model:
            try:
                current_index = self.models.index(current_model)
                table.cursor_cell = (current_index, 0)
            except (ValueError, IndexError):
                table.cursor_cell = (0, 0)

    def on_button_pressed(self, event: Button.Pressed) -> None:
        """Handle button presses in the modal."""
        if event.button.id == "close-btn":
            self.dismiss()
        elif event.button.id == "select-btn":
            self.select_current_model()

    def select_current_model(self) -> None:
        """Select the currently highlighted model and update the transcriber."""
        table = self.query_one("#models-table", DataTable)
        cursor_row, _ = table.cursor_cell

        if 0 <= cursor_row < len(self.models):
            selected_model = self.models[cursor_row]

            # Update the transcriber if available
            if self.transcriber:
                try:
                    # Update the transcriber's model name
                    old_model = self.transcriber.model_name
                    self.transcriber.model_name = selected_model

                    # Create a new WhisperModel instance with the selected model
                    device = "cuda" if _is_cuda_available() else "cpu"
                    compute_type = "float16" if device == "cuda" else "int8"
                    self.transcriber.model = WhisperModel(selected_model, device=device, compute_type=compute_type)

                    # Update the main screen's status to show the new model
                    main_screen = self.app.screen
                    if hasattr(main_screen, 'update_status'):
                        main_screen.update_status(f"âœ… Model changed from '{old_model}' to '{selected_model}'")

                    self.notify(f"âœ… Model updated: {selected_model}")
                    self.dismiss()
                except Exception as e:
                    self.notify(f"âŒ Error updating model: {e}", severity="error")
            else:
                self.notify(f"Selected model: {selected_model}")
                self.dismiss()


# %% ../nbs/00_cli.ipynb 17
app = typer.Typer()

@app.command()
def hello(name: str):
    """Simple greeting command for testing and demonstration.

    This command serves as a basic functionality test and demonstrates
    the CLI framework integration. It provides a simple entry point
    for users to verify system setup and command routing.

    Args:
        name: Name to include in the greeting message

    Example:
        python -m tui_writer.cli hello "World"
        # Output: Hello World
    """
    print(f"Hello {name}")

@app.command()
def tui():
    """Launch the interactive audio transcription interface.

    Starts the full-featured Textual TUI for audio transcription. This
    command launches the complete user interface with real-time recording,
    model selection, and transcription capabilities.

    The TUI provides:
    - Interactive recording with live feedback
    - Model selection and management
    - Real-time transcription results
    - Clipboard integration for easy result access

    Use this command when you need the full transcription experience
    with visual feedback and interactive controls.
    """
    tui_app = TranscriptionTUI()
    tui_app.run()

@app.command()
def transcribe_last():
    """Process the most recently recorded audio file.

    This command transcribes the last recorded audio file without
    starting a new recording session. It's useful for batch processing
    or when you want to re-transcribe existing audio files.

    The command:
    1. Locates the most recent audio recording
    2. Validates file existence and format
    3. Performs transcription using current model settings
    4. Copies results to clipboard
    5. Displays processing metrics

    Exit Codes:
        0: Success - transcription completed successfully
        1: Error - file not found, invalid format, or processing failure
    """
    try:
        recorder = AudioRecorder()
        audio_file_path = recorder._get_audio_file_path()
        if not audio_file_path.exists():
            console.print(
                "âŒ [bold red]No previous recording found. Record audio first by running 'hns' without --last flag.[/bold red]"
            )
            sys.exit(1)

        transcriber = WhisperTranscriber()
        transcription, elapsed_time = transcriber.transcribe(audio_file_path)

        copy_to_clipboard(transcription, elapsed_time)

    except (RuntimeError, ValueError) as e:
        console.print(f"âŒ [bold red]{e}[/bold red]")
        sys.exit(1)
    except Exception as e:
        console.print(f"âŒ [bold red]Unexpected error: {e}[/bold red]")
        sys.exit(1)


