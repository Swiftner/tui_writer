# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_live.ipynb.

# %% auto 0
__all__ = ['get_device', 'load_silero_vad', 'LiveTranscriber']

# %% ../nbs/03_live.ipynb 4
import logging
import asyncio
from typing import Optional, Callable
from queue import Queue

import numpy as np
import pyaudio
import torch
from faster_whisper import WhisperModel

def get_device(force_cpu: bool = False) -> str:
    """Pick best available device."""
    if force_cpu:
        return "cpu"
    if torch.cuda.is_available():
        return "cuda"
    if torch.backends.mps.is_available():
        try:
            torch.mps.empty_cache()
        except Exception:
            pass
        return "mps"
    return "cpu"

def load_silero_vad():
    """Load Silero VAD model from torch hub."""
    try:
        model, _utils = torch.hub.load(
            repo_or_dir='snakers4/silero-vad',
            model='silero_vad',
            force_reload=False,
            onnx=False
        )
        return model
    except Exception as e:
        logging.warning(f"Failed to load Silero VAD: {e}")
        return None

# %% ../nbs/03_live.ipynb 7
class LiveTranscriber:
    """Live audio transcription for TUI applications using PyAudio and Whisper with Silero VAD-based chunking."""
    
    def __init__(
        self, 
        model_id: str = "openai/whisper-base",
        language: str = "en",
        force_cpu: bool = False,
        on_transcript: Optional[Callable[[str], None]] = None,
        vad_threshold: float = 0.5,
        min_speech_duration_ms: int = 250,
        min_silence_duration_ms: int = 500,
    ):
        
        self.logger = logging.getLogger(__name__)
        self.on_transcript = on_transcript
        
        self.model_id = model_id
        self.language = language

        # Fixed 16 kHz sample rate (required by Silero + Whisper)
        self.sample_rate = 16000
        
        # Device + ASR model
        self.device = get_device(force_cpu=force_cpu)
        self.transcribe_model = WhisperModel(
            self.model_id,
            device=self.device,
            compute_type="int8" if self.device == "cpu" else "float16", # use "float32" on MPS if needed
        )


        # Load Silero VAD
        self.vad_threshold = vad_threshold
        self.silero_model = load_silero_vad()
        if self.silero_model is None:
            raise RuntimeError("Silero VAD failed to load. Cannot continue.")

        # Thresholds (in samples)
        self.min_speech_samples = int(self.sample_rate * min_speech_duration_ms / 1000)
        self.min_silence_samples = int(self.sample_rate * min_silence_duration_ms / 1000)

        # Buffers and state
        self.audio_queue: "Queue[np.ndarray]" = Queue()
        self.is_running = False

        self.is_speech_active = False
        self.speech_buffer = np.array([], dtype=np.float32)
        self.silence_counter = 0

        self.logger.info(f"Initialized LiveTranscriber (model={model_id}, device={self.device}, sample_rate=16kHz, VAD=Silero)")
    
    def _detect_speech_silero(self, audio_chunk: np.ndarray) -> bool:
        """Return True if speech detected; False on low prob or on error."""
        try:
            audio_tensor = torch.from_numpy(audio_chunk).float()
            prob = self.silero_model(audio_tensor, self.sample_rate).item()
            return prob > self.vad_threshold
        except Exception as e:
            self.logger.warning(f"Silero VAD error: {e}")
            return False
    
    def _transcribe_chunk(self, audio_data: np.ndarray) -> str:
        segments, _info = self.transcribe_model.transcribe(
            audio_data,
            language=self.language,
            beam_size=1,
            condition_on_previous_text=False,
            vad_filter=True, # we already did VAD; set True if you want extra internal filtering
            vad_parameters=dict(
                threshold=0.4,
                min_speech_duration_ms=self.min_speech_samples * 1000 // self.sample_rate,
                max_speech_duration_s=float("inf"),
                min_silence_duration_ms=200,
            ),
        )
        return " ".join(s.text.strip() for s in segments).strip()
    
    def audio_callback(self, in_data, frame_count, time_info, status):
        """Called automatically by PyAudio for each audio frame."""
        if status:
            self.logger.debug(f"Audio callback status: {status}")
        audio = np.frombuffer(in_data, dtype=np.int16).astype(np.float32) / 32768.0
        self.audio_queue.put(audio)
        return in_data, pyaudio.paContinue
    
    async def process_audio(self):
        """Process queued audio in real-time with VAD chunking."""
        while self.is_running:
            if self.audio_queue.empty():
                await asyncio.sleep(0.01)
                continue

            chunk = self.audio_queue.get()
            if self._detect_speech_silero(chunk):
                if not self.is_speech_active:
                    self.is_speech_active = True
                    self.speech_buffer = chunk.copy()
                    self.silence_counter = 0
                else:
                    self.speech_buffer = np.append(self.speech_buffer, chunk)
                    self.silence_counter = 0
            else:
                if self.is_speech_active:
                    self.silence_counter += len(chunk)
                    self.speech_buffer = np.append(self.speech_buffer, chunk)

                    if self.silence_counter >= self.min_silence_samples:
                        if len(self.speech_buffer) >= self.min_speech_samples:
                            text = await asyncio.to_thread(self._transcribe_chunk, self.speech_buffer)
                            if text and self.on_transcript:
                                if asyncio.iscoroutinefunction(self.on_transcript):
                                    await self.on_transcript(text)
                                else:
                                    self.on_transcript(text)
                        # reset
                        self.is_speech_active = False
                        self.speech_buffer = np.array([], dtype=np.float32)
                        self.silence_counter = 0
    
    async def start(self):
        """Start recording and transcription loop."""
        self.is_running = True
        audio = pyaudio.PyAudio()
        try:
            stream = audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=512,
                stream_callback=self.audio_callback,
            )
            stream.start_stream()
            try:
                await self.process_audio()
            finally:
                stream.stop_stream()
                stream.close()
        finally:
            audio.terminate()

    def stop(self):
        self.is_running = False
