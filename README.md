# TUI Writer


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Developer Guide

If you are new to using `nbdev` here are some useful pointers to get you
started.

### Install tui_writer in Development mode

``` sh
# make sure tui_writer package is installed in development mode
$ pip install -e .

# make changes under nbs/ directory
# ...

# compile to have changes apply to tui_writer
$ nbdev_prepare
```

## Usage

### Installation

Install latest from the GitHub
[repository](https://github.com/Swiftner/tui_writer):

``` sh
$ pip install git+https://github.com/Swiftner/tui_writer.git
```

or from [conda](https://anaconda.org/Swiftner/tui_writer)

``` sh
$ conda install -c Swiftner tui_writer
```

or from [pypi](https://pypi.org/project/tui_writer/)

``` sh
$ pip install tui_writer
```

### Documentation

Documentation can be found hosted on this GitHub
[repository](https://github.com/Swiftner/tui_writer)’s
[pages](https://Swiftner.github.io/tui_writer/). Additionally you can
find package manager specific guidelines on
[conda](https://anaconda.org/Swiftner/tui_writer) and
[pypi](https://pypi.org/project/tui_writer/) respectively.

## Development Plan: Real-Time Transcription with LLM Integration

### Current State

TUI Writer currently supports basic live transcription using FastRTC
with speech-to-text models. The system can detect pauses and transcribe
audio in real-time, but lacks LLM integration for intelligent text
processing and iterative refinement.

### Development Philosophy: MVP-First Approach

**Focus on understanding and user experience over raw speed. Build a
great Minimum Viable Product that demonstrates the core concept of
AI-assisted writing through natural conversation patterns.**

### Core MVP Goal

**Create a TUI where users can speak naturally, see their words
transcribed in real-time, and engage in a conversation with an LLM that
helps refine and improve their text collaboratively.**

### Key Features to Implement

#### Phase 1: Core TUI Transcription Experience

- [ ] Create intuitive TUI layout showing live transcription
- [ ] Implement basic pause detection for natural speech flow
- [ ] Add simple text buffer that accumulates speech
- [ ] Show clear visual feedback during transcription

#### Phase 2: LLM Integration & Conversation

- [ ] Connect LLM to transcribed text for intelligent suggestions
- [ ] Implement conversation context that remembers previous exchanges
- [ ] Create natural language prompts for text improvement
- [ ] Add simple suggestion display in TUI

#### Phase 3: Interactive Text Refinement

- [ ] Build text editing workflow (accept/modify/discard suggestions)
- [ ] Implement iterative refinement - speak more, get better
  suggestions
- [ ] Add conversation memory for context-aware improvements
- [ ] Create intuitive keyboard shortcuts for text management

#### Phase 4: Polish & User Experience

- [ ] Add helpful onboarding and usage instructions
- [ ] Implement error handling and recovery
- [ ] Add configuration options for different use cases
- [ ] Create demo modes and examples

### Technical Architecture

#### Core Components

    ┌─────────────────┐    ┌─────────────────────────────────────┐    ┌─────────────────┐
    │     Audio       │───▶│         FastRTC +                   │───▶│      LLM        │
    │     Input       │    │     Pause Detector                  │    │   Processing    │
    └─────────────────┘    │                                     │    └─────────────────┘
                           │   ┌─────────────────────────────────┐ │              │
                           │   │       Transcribes               │ │              │
                           │   │       in Chunks                 │ │              │
                           │   └─────────────────────────────────┘ │              │
                           └─────────────────────────────────────┘              │
                                                                                │
    ┌─────────────────┐                                                         │
    │   Text Block    │◀──────────────────────────────────────────────────────────┘
    │   Management    │
    └─────────────────┘

#### Data Flow

1.  **Audio Capture** → FastRTC streams continuous audio input
2.  **Real-time Processing** → Pause Detector identifies speech segments
    and silence gaps
3.  **Chunked Transcription** → Audio transcribed in manageable chunks
    during/after speech
4.  **LLM Integration** → Each transcribed chunk sent to LLM for
    intelligent processing
5.  **Text Block Updates** → LLM-refined text updates the main text
    buffer
6.  **Continuous Loop** → Process repeats with each new speech chunk for
    iterative refinement

### Integration Points

#### With Existing TUI Writer Components

- **CLI Module**: Add real-time transcription commands
- **AI Module**: Extend for LLM integration
- **Live Module**: Enhance current FastRTC implementation

#### External Dependencies

- **fastrtc**: Real-time audio streaming
- **faster_whisper**: Fast speech-to-text
- **openai/smolagents**: LLM integration
- **rich**: Enhanced terminal UI for text display

### Testing Strategy

#### Unit Tests

- [ ] Audio processing pipeline tests
- [ ] LLM integration mocking
- [ ] Text merge/diff algorithms

#### Integration Tests

- [ ] End-to-end transcription workflow
- [ ] Multi-provider LLM testing
- [ ] Performance benchmarking

#### User Experience Tests

- [ ] Real-time responsiveness validation
- [ ] Text quality assessment
- [ ] Error handling verification

### Success Metrics

#### MVP Quality Targets

- **Natural Conversation Flow**: Users can speak naturally without
  timing pressures
- **Clear Transcription Display**: Text appears in real-time as user
  speaks
- **Helpful LLM Suggestions**: AI provides meaningful improvements to
  text
- **Intuitive TUI Experience**: Users understand how to interact with
  the system

#### User Experience Focus

- **Forgiving Interaction**: Works well even with imperfect speech or
  pauses
- **Clear Feedback**: Users always know what’s happening (transcribing,
  processing, ready)
- **Helpful Guidance**: System suggests improvements without being
  overwhelming
- **Easy Text Management**: Simple commands to accept, edit, or discard
  suggestions

### Getting Started with Development

#### Prerequisites

``` bash
# Install development dependencies
uv add --dev jupyterlab ipykernel

# Install project in development mode
uv sync

# Run Jupyter Lab for development
uv run jupyter lab
```

#### Development Workflow

1.  **Start with live transcription** (`nbs/02_live.ipynb`)
2.  **Enhance pause detection** for better triggering
3.  **Add LLM integration** to existing transcription pipeline
4.  **Test iteratively** with real audio input
5.  **Refine UI/UX** based on testing feedback

#### Key Files to Modify

- `nbs/02_live.ipynb` - Core real-time transcription logic
- `nbs/01_ai.ipynb` - LLM integration and text processing
- `nbs/00_cli.ipynb` - Command-line interface updates
- `tui_writer/cli.py` - Main application entry point

### Next Steps

1.  **Review current live transcription implementation**
2.  **Identify specific areas for LLM integration**
3.  **Start with simple text refinement after pauses**
4.  **Iteratively add more sophisticated features**

This development plan provides a structured approach to building an
intelligent real-time transcription system with LLM-powered text
refinement, transforming TUI Writer into a powerful collaborative
writing tool.

## How to use

Fill me in please! Don’t forget code examples:

### Live Transcription with FastRTC

TUI Writer supports live transcription functionality through
[FastRTC](https://fastrtc.org/userguide/audio/), a powerful real-time
audio streaming library. This enables real-time speech-to-text
capabilities with advanced features like pause detection, interrupt
handling, and telephone integration.

#### Adding Live Transcription

To add live transcription capabilities using FastRTC:

1.  **Install FastRTC with audio dependencies:**

``` bash
pip install fastrtc[stt,tts]
```

2.  **Basic live transcription setup:**

``` python
from fastrtc import Stream, ReplyOnPause, get_stt_model
import numpy as np

# Initialize speech-to-text model
stt_model = get_stt_model(model="moonshine/base")

def live_transcribe(audio: tuple[int, np.ndarray]) -> str:
    """Process live audio and return transcription"""
    sample_rate, audio_array = audio
    return stt_model.stt(audio)

# Create FastRTC stream with live transcription
stream = Stream(
    handler=ReplyOnPause(live_transcribe),
    modality="audio",
    mode="send-receive"
)

# Mount to your FastAPI app
# stream.mount(app)
```

3.  **Advanced configuration with pause detection:**

``` python
from fastrtc import Stream, ReplyOnPause, AlgoOptions, SileroVadOptions

def enhanced_transcribe(audio: tuple[int, np.ndarray]) -> str:
    """Enhanced transcription with better pause detection"""
    sample_rate, audio_array = audio
    return stt_model.stt(audio)

stream = Stream(
    handler=ReplyOnPause(
        enhanced_transcribe,
        algo_options=AlgoOptions(
            audio_chunk_duration=0.6,
            started_talking_threshold=0.2,
            speech_threshold=0.1
        ),
        model_options=SileroVadOptions(
            threshold=0.5,
            min_speech_duration_ms=250,
            min_silence_duration_ms=100
        )
    ),
    modality="audio",
    mode="send-receive"
)
```

#### Key Features

- **Real-time processing**: Audio is processed as you speak
- **Pause detection**: Automatically detects when you stop speaking
- **Interrupt handling**: Can be interrupted by speaking again
- **Telephone integration**: Works with SIP providers like Twilio
- **Customizable voice activity detection**: Fine-tune sensitivity and
  timing

#### Integration with TUI Writer

The live transcription functionality integrates seamlessly with TUI
Writer’s existing text editing capabilities, allowing you to: -
Transcribe speech in real-time - Edit transcribed text interactively -
Use voice commands for text manipulation - Maintain conversation history
for context

For more detailed examples and advanced configurations, see the [FastRTC
Audio Streaming Guide](https://fastrtc.org/userguide/audio/).
